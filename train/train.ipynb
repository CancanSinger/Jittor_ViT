{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cda36f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[i 1023 17:32:01.671895 60 log.cc:351] Load log_sync: 1\u001b[m\n",
      "\u001b[38;5;2m[i 1023 17:32:01.716431 60 compiler.py:956] Jittor(1.3.10.0) src: /home/jittor/SCC_Model/ViT/.venv/lib/python3.10/site-packages/jittor\u001b[m\n",
      "\u001b[38;5;2m[i 1023 17:32:01.721645 60 compiler.py:957] g++ at /usr/bin/g++(11.4.0)\u001b[m\n",
      "\u001b[38;5;2m[i 1023 17:32:01.722571 60 compiler.py:958] cache_path: /home/jittor/.cache/jittor/jt1.3.10/g++11.4.0/py3.10.12/Linux-6.6.87.2x4a/AMDRyzen97940Hxd7/fa38/main\u001b[m\n",
      "\u001b[38;5;2m[i 1023 17:32:01.808233 60 install_cuda.py:96] cuda_driver_version: [12, 9]\u001b[m\n",
      "\u001b[38;5;2m[i 1023 17:32:01.809893 60 install_cuda.py:82] needed restart but not /home/jittor/SCC_Model/ViT/.venv/bin/python ['-m', 'ipykernel_launcher', '--f=/mnt/wslg/runtime-dir/jupyter/runtime/kernel-v3a793248b0c6aa437f4e8f4f6bdb5520012a1e183.json'], you can ignore this warning.\u001b[m\n",
      "\u001b[38;5;2m[i 1023 17:32:01.821657 60 __init__.py:412] Found /home/jittor/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc(12.2.140) at /home/jittor/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc.\u001b[m\n",
      "\u001b[38;5;2m[i 1023 17:32:01.872842 60 __init__.py:412] Found addr2line(2.38) at /usr/bin/addr2line.\u001b[m\n",
      "\u001b[38;5;2m[i 1023 17:32:01.942623 60 compiler.py:1013] cuda key:cu12.2.140\u001b[m\n",
      "\u001b[38;5;2m[i 1023 17:32:02.580592 60 __init__.py:227] Total mem: 7.37GB, using 2 procs for compiling.\u001b[m\n",
      "\u001b[38;5;2m[i 1023 17:32:02.981216 60 jit_compiler.cc:28] Load cc_path: /usr/bin/g++\u001b[m\n",
      "\u001b[38;5;2m[i 1023 17:32:03.253423 60 init.cc:63] Found cuda archs: [89,]\u001b[m\n"
     ]
    }
   ],
   "source": [
    "import jittor as jt\n",
    "from jittor import nn\n",
    "from numpy import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf344468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "current_dir = os.path.abspath('.')\n",
    "project_root = os.path.dirname(current_dir)\n",
    "\n",
    "if project_root in sys.path:\n",
    "    sys.path.remove(project_root)\n",
    "\n",
    "sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecd4fa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import TomatoDataset\n",
    "from data_loader import get_dataloader\n",
    "from models.vit_model import Visual_Transformer\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f2ddaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfdb11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[i 1023 17:32:03.857006 60 cuda_flags.cc:55] CUDA enabled.\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Configuration\n",
      "============================================================\n",
      "Device: GPU\n",
      "Batch Size: 16\n",
      "Learning Rate: 0.001\n",
      "Epochs: 50\n",
      "Image Size: 224\n",
      "============================================================\n",
      "\n",
      "Loading datasets...\n",
      "\n",
      "Creating model...\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Learning Rate: 0.001000\n",
      "\n",
      "============================================================\n",
      "Epoch [1/50] - Training\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Compiling Operators(28/83) used: 3.31s eta: 6.51s 47/83) used: 5.32s eta: 4.07s 49/83) used: 9.32s eta: 6.47s 51/83) used: 13.3s eta: 8.37s 52/83) used: 15.3s eta: 9.14s 53/83) used: 17.3s eta: 9.82s 54/83) used: 19.3s eta: 10.4s 55/83) used: 20.4s eta: 10.4s 56/83) used: 23.4s eta: 11.3s 57/83) used: 24.4s eta: 11.1s 58/83) used: 27.4s eta: 11.8s 59/83) used: 28.4s eta: 11.5s 60/83) used: 30.4s eta: 11.6s 61/83) used: 31.4s eta: 11.3s 62/83) used: 33.4s eta: 11.3s 63/83) used: 35.4s eta: 11.2s 65/83) used: 39.4s eta: 10.9s 66/83) used: 41.4s eta: 10.7s 67/83) used: 43.4s eta: 10.4s 68/83) used: 45.4s eta:   10s 69/83) used: 47.4s eta: 9.62s \r"
     ]
    }
   ],
   "source": [
    "# 设置随机种子\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    jt.set_global_seed(seed)\n",
    "\n",
    "# 计算准确率\n",
    "def calculate_accuracy(outputs, labels):\n",
    "    \"\"\"计算Top-1准确率\"\"\"\n",
    "    preds = jt.argmax(outputs, dim=1)[0]\n",
    "    correct = jt.sum(preds == labels).item()\n",
    "    total = labels.shape[0]\n",
    "    return correct / total\n",
    "\n",
    "# 训练一个epoch\n",
    "def train_epoch(model, train_loader, optimizer, epoch, total_epochs):\n",
    "    \"\"\"训练一个epoch\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    batch_count = 0\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Epoch [{epoch+1}/{total_epochs}] - Training\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        # 前向传播\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = nn.cross_entropy_loss(outputs, labels)\n",
    "        \n",
    "        # 反向传播\n",
    "        optimizer.step(loss)\n",
    "        \n",
    "        # 计算准确率\n",
    "        acc = calculate_accuracy(outputs, labels)\n",
    "        \n",
    "        # 累计统计\n",
    "        total_loss += float(loss)\n",
    "        total_acc += acc\n",
    "        batch_count += 1\n",
    "        \n",
    "        # 打印进度\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            avg_loss = total_loss / batch_count\n",
    "            avg_acc = total_acc / batch_count\n",
    "            print(f\"  Batch [{batch_idx+1}/{len(train_loader)}] \"\n",
    "                  f\"Loss: {avg_loss:.4f} | Acc: {avg_acc*100:.2f}%\")\n",
    "    \n",
    "    avg_loss = total_loss / batch_count\n",
    "    avg_acc = total_acc / batch_count\n",
    "    \n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "# 验证\n",
    "def validate(model, val_loader, epoch, total_epochs):\n",
    "    \"\"\"验证模型\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    batch_count = 0\n",
    "    \n",
    "    # 混淆矩阵\n",
    "    confusion_matrix = np.zeros((config.NUM_CLASSES, config.NUM_CLASSES), dtype=np.int32)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Epoch [{epoch+1}/{total_epochs}] - Validation\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    with jt.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            # 前向传播\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # 计算损失\n",
    "            loss = nn.cross_entropy_loss(outputs, labels)\n",
    "            \n",
    "            # 计算准确率\n",
    "            acc = calculate_accuracy(outputs, labels)\n",
    "            \n",
    "            # 更新混淆矩阵\n",
    "            preds = jt.argmax(outputs, dim=1)[0].numpy()\n",
    "            labels_np = labels.numpy()\n",
    "            for pred, label in zip(preds, labels_np):\n",
    "                confusion_matrix[int(label), int(pred)] += 1\n",
    "            \n",
    "            total_loss += float(loss)\n",
    "            total_acc += acc\n",
    "            batch_count += 1\n",
    "    \n",
    "    avg_loss = total_loss / batch_count\n",
    "    avg_acc = total_acc / batch_count\n",
    "    \n",
    "    print(f\"  Val Loss: {avg_loss:.4f} | Val Acc: {avg_acc*100:.2f}%\")\n",
    "    \n",
    "    # 打印每个类别的准确率\n",
    "    print(f\"\\n  Per-class Accuracy:\")\n",
    "    for i in range(config.NUM_CLASSES):\n",
    "        class_correct = confusion_matrix[i, i]\n",
    "        class_total = confusion_matrix[i, :].sum()\n",
    "        class_acc = class_correct / class_total if class_total > 0 else 0\n",
    "        print(f\"    {CLASS_NAMES[i]:<25}: {class_acc*100:>6.2f}% ({class_correct}/{class_total})\")\n",
    "    \n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "# 主训练函数\n",
    "def train():\n",
    "    \"\"\"主训练流程\"\"\"\n",
    "    \n",
    "    # 设置设备\n",
    "    jt.flags.use_cuda = 1 if jt.has_cuda else 0\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training Configuration\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Device: {'GPU' if jt.flags.use_cuda else 'CPU'}\")\n",
    "    print(f\"Batch Size: {config.BATCH_SIZE}\")\n",
    "    print(f\"Learning Rate: {config.LEARNING_RATE}\")\n",
    "    print(f\"Epochs: 50\")  # 默认50轮训练\n",
    "    print(f\"Image Size: {config.IMG_SIZE}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # 设置随机种子\n",
    "    set_seed(42)\n",
    "    \n",
    "    # 创建保存目录\n",
    "    save_dir = 'checkpoints'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # 加载数据\n",
    "    print(\"Loading datasets...\")\n",
    "    train_loader = get_dataloader(\n",
    "        root_dir= project_root+'/tomato_yolo_dataset',  # 默认数据集路径\n",
    "        mode='train',\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        img_size=config.IMG_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    val_loader = get_dataloader(\n",
    "        root_dir=project_root+'/tomato_yolo_dataset',  # 默认数据集路径\n",
    "        mode='val',\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        img_size=config.IMG_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    # 创建模型\n",
    "    print(\"\\nCreating model...\")\n",
    "    model = Visual_Transformer(\n",
    "        img_size=config.IMG_SIZE,\n",
    "        patch_size=config.PATCH_SIZE,\n",
    "        in_channels=config.IN_CHANNELS,\n",
    "        embed_dim=config.EMBED_DIM,\n",
    "        depth=config.NUM_LAYERS,\n",
    "        num_heads=config.NUM_HEADS,\n",
    "        dropout_rate=config.DROPOUT,\n",
    "        hidden_dim=config.MLP_Hidden_Dim\n",
    "    )\n",
    "    \n",
    "    # 优化器\n",
    "    optimizer = nn.Adam(\n",
    "        model.parameters(),\n",
    "        lr=config.LEARNING_RATE,\n",
    "        weight_decay=1e-4\n",
    "    )\n",
    "    \n",
    "    # 学习率调度器（余弦退火）\n",
    "    def adjust_learning_rate(optimizer, epoch, total_epochs, base_lr):\n",
    "        \"\"\"余弦退火学习率\"\"\"\n",
    "        lr = base_lr * 0.5 * (1.0 + np.cos(np.pi * epoch / total_epochs))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        return lr\n",
    "    \n",
    "    # 训练历史\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'lr': []\n",
    "    }\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    total_epochs = 50  # 默认训练50轮\n",
    "    \n",
    "    # 训练循环\n",
    "    print(\"\\nStarting training...\\n\")\n",
    "    for epoch in range(total_epochs):\n",
    "        # 调整学习率\n",
    "        current_lr = adjust_learning_rate(\n",
    "            optimizer, epoch, total_epochs, config.LEARNING_RATE\n",
    "        )\n",
    "        print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "        \n",
    "        # 训练\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, train_loader, optimizer, epoch, total_epochs\n",
    "        )\n",
    "        \n",
    "        # 验证\n",
    "        val_loss, val_acc = validate(\n",
    "            model, val_loader, epoch, total_epochs\n",
    "        )\n",
    "        \n",
    "        # 记录历史\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['lr'].append(current_lr)\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch = epoch\n",
    "            \n",
    "            model_path = os.path.join(save_dir, 'best_model.pkl')\n",
    "            jt.save(model.state_dict(), model_path)\n",
    "            print(f\"\\n  ✓ Best model saved! Val Acc: {best_val_acc*100:.2f}%\")\n",
    "        \n",
    "        # 定期保存checkpoint\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            checkpoint_path = os.path.join(save_dir, f'checkpoint_epoch_{epoch+1}.pkl')\n",
    "            jt.save(model.state_dict(), checkpoint_path)\n",
    "            print(f\"  ✓ Checkpoint saved: {checkpoint_path}\")\n",
    "        \n",
    "        print(f\"\\n  Summary: Train Acc: {train_acc*100:.2f}% | \"\n",
    "              f\"Val Acc: {val_acc*100:.2f}% | \"\n",
    "              f\"Best Val Acc: {best_val_acc*100:.2f}% (Epoch {best_epoch+1})\")\n",
    "    \n",
    "    # 保存最终模型\n",
    "    final_model_path = os.path.join(save_dir, 'final_model.pkl')\n",
    "    jt.save(model.state_dict(), final_model_path)\n",
    "    \n",
    "    # 保存训练历史\n",
    "    history_path = os.path.join(save_dir, 'training_history.json')\n",
    "    with open(history_path, 'w') as f:\n",
    "        # 转换numpy类型为Python原生类型\n",
    "        history_serializable = {\n",
    "            k: [float(v) for v in values] for k, values in history.items()\n",
    "        }\n",
    "        json.dump(history_serializable, f, indent=4)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training Complete!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc*100:.2f}% (Epoch {best_epoch+1})\")\n",
    "    print(f\"Best model saved to: {os.path.join(save_dir, 'best_model.pkl')}\")\n",
    "    print(f\"Training history saved to: {history_path}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec79ecc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
