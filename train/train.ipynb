{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "658c7e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[i 1025 10:53:29.945191 28 log.cc:351] Load log_sync: 1\u001b[m\n",
      "\u001b[38;5;2m[i 1025 10:53:29.983234 28 compiler.py:956] Jittor(1.3.10.0) src: /home/jittor/SCC_Model/ViT/.venv/lib/python3.10/site-packages/jittor\u001b[m\n",
      "\u001b[38;5;2m[i 1025 10:53:29.987114 28 compiler.py:957] g++ at /usr/bin/g++(11.4.0)\u001b[m\n",
      "\u001b[38;5;2m[i 1025 10:53:29.988391 28 compiler.py:958] cache_path: /home/jittor/.cache/jittor/jt1.3.10/g++11.4.0/py3.10.12/Linux-6.6.87.2x4a/AMDRyzen97940Hxd7/fa38/main\u001b[m\n",
      "\u001b[38;5;2m[i 1025 10:53:30.071170 28 install_cuda.py:96] cuda_driver_version: [12, 9]\u001b[m\n",
      "\u001b[38;5;2m[i 1025 10:53:30.072216 28 install_cuda.py:82] needed restart but not /home/jittor/SCC_Model/ViT/.venv/bin/python ['-m', 'ipykernel_launcher', '--f=/mnt/wslg/runtime-dir/jupyter/runtime/kernel-v32ef3d6586a2a48f22f791436a3f836d329519a05.json'], you can ignore this warning.\u001b[m\n",
      "\u001b[38;5;2m[i 1025 10:53:30.076601 28 __init__.py:412] Found /home/jittor/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc(12.2.140) at /home/jittor/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc.\u001b[m\n",
      "\u001b[38;5;2m[i 1025 10:53:30.124254 28 __init__.py:412] Found addr2line(2.38) at /usr/bin/addr2line.\u001b[m\n",
      "\u001b[38;5;2m[i 1025 10:53:30.198392 28 compiler.py:1013] cuda key:cu12.2.140\u001b[m\n",
      "\u001b[38;5;2m[i 1025 10:53:30.633069 28 __init__.py:227] Total mem: 7.37GB, using 2 procs for compiling.\u001b[m\n",
      "\u001b[38;5;2m[i 1025 10:53:30.745454 28 jit_compiler.cc:28] Load cc_path: /usr/bin/g++\u001b[m\n",
      "\u001b[38;5;2m[i 1025 10:53:30.995511 28 init.cc:63] Found cuda archs: [89,]\u001b[m\n",
      "\u001b[38;5;2m[i 1025 10:53:31.318850 28 cuda_flags.cc:55] CUDA enabled.\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸš€ è®­ç»ƒé…ç½®\n",
      "======================================================================\n",
      "è®¾å¤‡: ğŸ® GPU\n",
      "Batch Size: 8\n",
      "è®­ç»ƒè½®æ•°: 15\n",
      "è®­ç»ƒé‡‡æ ·ç‡: 20%\n",
      "éªŒè¯é‡‡æ ·ç‡: 20%\n",
      "======================================================================\n",
      "\n",
      "ğŸ“¦ åŠ è½½æ•°æ®...\n",
      "train æ•°æ®é›†: ä» 14527 ä¸ªæ ·æœ¬ä¸­é‡‡æ ·äº† 2905 ä¸ªæ ·æœ¬ (20.0%)\n",
      "val æ•°æ®é›†: ä» 3632 ä¸ªæ ·æœ¬ä¸­é‡‡æ ·äº† 726 ä¸ªæ ·æœ¬ (20.0%)\n",
      "âœ“ æ•°æ®åŠ è½½å®Œæˆ\n",
      "\n",
      "ğŸ” æ£€æŸ¥æ•°æ®é›†æ ‡ç­¾ï¼ˆå‰10ä¸ªbatchï¼‰...\n",
      "  âš ï¸  å‘ç° 8/80 ä¸ªå¼‚å¸¸æ ‡ç­¾ (10.0%)\n",
      "  è®­ç»ƒæ—¶ä¼šè‡ªåŠ¨è¿‡æ»¤\n",
      "\n",
      "ğŸ—ï¸  åˆ›å»ºæ¨¡å‹...\n",
      "  æµ‹è¯•å‰å‘ä¼ æ’­...\n",
      "  âœ“ æµ‹è¯•é€šè¿‡: [2,10,]\n",
      "\n",
      "======================================================================\n",
      "ğŸ¯ å¼€å§‹è®­ç»ƒ (10:53:31)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ğŸ“… Epoch [1/15]\n",
      "======================================================================\n",
      "\n",
      "ğŸ”¥ è®­ç»ƒä¸­...\n",
      "  â³ ç¬¬ä¸€ä¸ªbatch... âœ“ (0.4ç§’)\n",
      "  è¿›åº¦: 50 batches | Loss: 2.1742 | Acc: 30.8% | 14.6it/s\n",
      "  ğŸ“Š [50] Loss: 2.1742 | Acc: 30.75% | 14.6 batch/s\n",
      "  è¿›åº¦: 100 batches | Loss: 2.0259 | Acc: 34.4% | 16.1it/s\n",
      "  ğŸ“Š [100] Loss: 2.0259 | Acc: 34.38% | 16.1 batch/s\n",
      "  è¿›åº¦: 150 batches | Loss: 1.9632 | Acc: 34.7% | 16.7it/s\n",
      "  ğŸ“Š [150] Loss: 1.9632 | Acc: 34.67% | 16.7 batch/s\n",
      "  è¿›åº¦: 200 batches | Loss: 1.9217 | Acc: 34.9% | 17.0it/s\n",
      "  ğŸ“Š [200] Loss: 1.9217 | Acc: 34.94% | 17.0 batch/s\n",
      "  è¿›åº¦: 250 batches | Loss: 1.9163 | Acc: 34.8% | 17.3it/s\n",
      "  ğŸ“Š [250] Loss: 1.9163 | Acc: 34.80% | 17.3 batch/s\n",
      "  è¿›åº¦: 300 batches | Loss: 1.9106 | Acc: 34.5% | 17.5it/s\n",
      "  ğŸ“Š [300] Loss: 1.9106 | Acc: 34.46% | 17.5 batch/s\n",
      "  è¿›åº¦: 350 batches | Loss: 1.9101 | Acc: 34.4% | 17.6it/s\n",
      "  ğŸ“Š [350] Loss: 1.9101 | Acc: 34.36% | 17.6 batch/s\n",
      "  è¿›åº¦: 360 batches | Loss: 1.9133 | Acc: 34.3% | 17.7it/s\n",
      "\n",
      "  â„¹ï¸  æ£€æµ‹åˆ°è®­ç»ƒé›†å®é™…batchæ•°: 364\n",
      "\n",
      "\n",
      "  âœ… è®­ç»ƒå®Œæˆ (20.7ç§’)\n",
      "     éå†: 364 batches\n",
      "     æœ‰æ•ˆ: 364 batches\n",
      "     Loss: 1.9165 | Acc: 34.10%\n",
      "\n",
      "ğŸ” éªŒè¯ä¸­...\n",
      "  è¿›åº¦: 80 batches | Loss: 1.9615 | Acc: 27.5%\n",
      "\n",
      "  â„¹ï¸  æ£€æµ‹åˆ°éªŒè¯é›†å®é™…batchæ•°: 91\n",
      "\n",
      "\n",
      "  âœ… éªŒè¯å®Œæˆ (2.4ç§’)\n",
      "     éå†: 91 batches\n",
      "     æœ‰æ•ˆ: 91 batches\n",
      "     æ ·æœ¬: 716 ä¸ª (æ­£ç¡®: 106)\n",
      "     Loss: 1.9482\n",
      "     å‡†ç¡®ç‡: 14.80% (ç±»åˆ«ç»Ÿè®¡)\n",
      "     âš ï¸  Batchå¹³å‡: 28.98% (å¯èƒ½ä¸å‡†ç¡®)\n",
      "     å¹³è¡¡å‡†ç¡®ç‡: 9.97%\n",
      "\n",
      "\n",
      "  ğŸ‰ æ–°æœ€ä½³! å¹³è¡¡å‡†ç¡®ç‡: 9.97% (â†‘9.97%)\n",
      "\n",
      "  â±ï¸  æœ¬è½®: 0.4min | å·²ç”¨: 0.4min | å‰©ä½™: 5.5min\n",
      "  ğŸ“… é¢„è®¡å®Œæˆ: 10:59:24\n",
      "\n",
      "======================================================================\n",
      "ğŸ“… Epoch [2/15]\n",
      "======================================================================\n",
      "\n",
      "ğŸ”¥ è®­ç»ƒä¸­...\n",
      "  â³ ç¬¬ä¸€ä¸ªbatch... âœ“ (0.0ç§’)\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 13.7% Loss: 1.9122 | Acc: 34.0% | 18.7it/s | ETA: 16s\n",
      "  ğŸ“Š [50/364] Loss: 1.9122 | Acc: 34.00% | 18.7 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 27.5% Loss: 1.8747 | Acc: 35.9% | 18.7it/s | ETA: 14s\n",
      "  ğŸ“Š [100/364] Loss: 1.8747 | Acc: 35.88% | 18.7 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 41.2% Loss: 1.8277 | Acc: 37.2% | 18.7it/s | ETA: 11s\n",
      "  ğŸ“Š [150/364] Loss: 1.8277 | Acc: 37.25% | 18.7 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 54.9% Loss: 1.7678 | Acc: 39.9% | 18.7it/s | ETA: 8ss\n",
      "  ğŸ“Š [200/364] Loss: 1.7678 | Acc: 39.94% | 18.7 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 68.7% Loss: 1.7395 | Acc: 40.9% | 18.6it/s | ETA: 6s\n",
      "  ğŸ“Š [250/364] Loss: 1.7395 | Acc: 40.95% | 18.6 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 82.4% Loss: 1.7283 | Acc: 40.9% | 18.7it/s | ETA: 3s\n",
      "  ğŸ“Š [300/364] Loss: 1.7283 | Acc: 40.88% | 18.7 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘| 96.2% Loss: 1.7246 | Acc: 41.2% | 18.7it/s | ETA: 0s\n",
      "  ğŸ“Š [350/364] Loss: 1.7246 | Acc: 41.18% | 18.7 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘| 98.9% Loss: 1.7213 | Acc: 41.2% | 18.7it/s | ETA: 0s\n",
      "\n",
      "  âœ… è®­ç»ƒå®Œæˆ (19.5ç§’)\n",
      "     éå†: 364 batches\n",
      "     æœ‰æ•ˆ: 364 batches\n",
      "     Loss: 1.7199 | Acc: 41.35%\n",
      "\n",
      "ğŸ” éªŒè¯ä¸­...\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘| 87.9% Loss: 1.6077 | Acc: 45.0%\n",
      "\n",
      "  âœ… éªŒè¯å®Œæˆ (2.3ç§’)\n",
      "     éå†: 91 batches\n",
      "     æœ‰æ•ˆ: 91 batches\n",
      "     æ ·æœ¬: 726 ä¸ª (æ­£ç¡®: 114)\n",
      "     Loss: 1.5778\n",
      "     å‡†ç¡®ç‡: 15.70% (ç±»åˆ«ç»Ÿè®¡)\n",
      "     âš ï¸  Batchå¹³å‡: 45.33% (å¯èƒ½ä¸å‡†ç¡®)\n",
      "     å¹³è¡¡å‡†ç¡®ç‡: 11.83%\n",
      "\n",
      "\n",
      "  ğŸ‰ æ–°æœ€ä½³! å¹³è¡¡å‡†ç¡®ç‡: 11.83% (â†‘1.86%)\n",
      "\n",
      "  â±ï¸  æœ¬è½®: 0.4min | å·²ç”¨: 0.8min | å‰©ä½™: 4.9min\n",
      "  ğŸ“… é¢„è®¡å®Œæˆ: 10:59:13\n",
      "\n",
      "======================================================================\n",
      "ğŸ“… Epoch [3/15]\n",
      "======================================================================\n",
      "\n",
      "ğŸ”¥ è®­ç»ƒä¸­...\n",
      "  â³ ç¬¬ä¸€ä¸ªbatch... âœ“ (0.0ç§’)\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 13.7% Loss: 1.5675 | Acc: 46.2% | 18.6it/s | ETA: 16s\n",
      "  ğŸ“Š [50/364] Loss: 1.5675 | Acc: 46.25% | 18.6 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 27.5% Loss: 1.5596 | Acc: 45.4% | 18.7it/s | ETA: 14s\n",
      "  ğŸ“Š [100/364] Loss: 1.5596 | Acc: 45.38% | 18.7 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 41.2% Loss: 1.5796 | Acc: 45.1% | 18.6it/s | ETA: 11s\n",
      "  ğŸ“Š [150/364] Loss: 1.5796 | Acc: 45.08% | 18.6 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 54.9% Loss: 1.6134 | Acc: 43.6% | 18.5it/s | ETA: 8ss\n",
      "  ğŸ“Š [200/364] Loss: 1.6134 | Acc: 43.62% | 18.5 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 68.7% Loss: 1.6229 | Acc: 43.0% | 18.4it/s | ETA: 6s\n",
      "  ğŸ“Š [250/364] Loss: 1.6229 | Acc: 42.95% | 18.4 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 82.4% Loss: 1.6401 | Acc: 42.5% | 18.2it/s | ETA: 3s\n",
      "  ğŸ“Š [300/364] Loss: 1.6401 | Acc: 42.50% | 18.2 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘| 96.2% Loss: 1.6335 | Acc: 43.1% | 18.1it/s | ETA: 0s\n",
      "  ğŸ“Š [350/364] Loss: 1.6335 | Acc: 43.14% | 18.1 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘| 98.9% Loss: 1.6282 | Acc: 43.6% | 18.1it/s | ETA: 0s\n",
      "\n",
      "  âœ… è®­ç»ƒå®Œæˆ (20.1ç§’)\n",
      "     éå†: 364 batches\n",
      "     æœ‰æ•ˆ: 364 batches\n",
      "     Loss: 1.6338 | Acc: 43.34%\n",
      "\n",
      "ğŸ” éªŒè¯ä¸­...\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘| 87.9% Loss: 1.4921 | Acc: 46.7%\n",
      "\n",
      "  âœ… éªŒè¯å®Œæˆ (2.6ç§’)\n",
      "     éå†: 91 batches\n",
      "     æœ‰æ•ˆ: 91 batches\n",
      "     æ ·æœ¬: 726 ä¸ª (æ­£ç¡®: 112)\n",
      "     Loss: 1.4775\n",
      "     å‡†ç¡®ç‡: 15.43% (ç±»åˆ«ç»Ÿè®¡)\n",
      "     âš ï¸  Batchå¹³å‡: 47.12% (å¯èƒ½ä¸å‡†ç¡®)\n",
      "     å¹³è¡¡å‡†ç¡®ç‡: 11.53%\n",
      "\n",
      "\n",
      "  â±ï¸  æœ¬è½®: 0.4min | å·²ç”¨: 1.1min | å‰©ä½™: 4.5min\n",
      "  ğŸ“… é¢„è®¡å®Œæˆ: 10:59:13\n",
      "\n",
      "======================================================================\n",
      "ğŸ“… Epoch [4/15]\n",
      "======================================================================\n",
      "\n",
      "ğŸ”¥ è®­ç»ƒä¸­...\n",
      "  â³ ç¬¬ä¸€ä¸ªbatch... âœ“ (0.0ç§’)\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 13.7% Loss: 1.5178 | Acc: 47.5% | 17.2it/s | ETA: 18s\n",
      "  ğŸ“Š [50/364] Loss: 1.5178 | Acc: 47.50% | 17.2 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 27.5% Loss: 1.5272 | Acc: 47.9% | 17.5it/s | ETA: 15s\n",
      "  ğŸ“Š [100/364] Loss: 1.5272 | Acc: 47.88% | 17.5 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 41.2% Loss: 1.5448 | Acc: 47.2% | 17.7it/s | ETA: 12s\n",
      "  ğŸ“Š [150/364] Loss: 1.5448 | Acc: 47.25% | 17.7 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 54.9% Loss: 1.5401 | Acc: 47.7% | 17.8it/s | ETA: 9ss\n",
      "  ğŸ“Š [200/364] Loss: 1.5401 | Acc: 47.69% | 17.8 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 68.7% Loss: 1.5388 | Acc: 47.9% | 17.8it/s | ETA: 6s\n",
      "  ğŸ“Š [250/364] Loss: 1.5388 | Acc: 47.85% | 17.8 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 82.4% Loss: 1.5473 | Acc: 47.5% | 17.9it/s | ETA: 3s\n",
      "  ğŸ“Š [300/364] Loss: 1.5473 | Acc: 47.46% | 17.9 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘| 96.2% Loss: 1.5475 | Acc: 47.1% | 18.0it/s | ETA: 0s\n",
      "  ğŸ“Š [350/364] Loss: 1.5475 | Acc: 47.14% | 18.0 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘| 98.9% Loss: 1.5533 | Acc: 47.0% | 18.0it/s | ETA: 0s\n",
      "\n",
      "  âœ… è®­ç»ƒå®Œæˆ (20.2ç§’)\n",
      "     éå†: 364 batches\n",
      "     æœ‰æ•ˆ: 364 batches\n",
      "     Loss: 1.5549 | Acc: 46.94%\n",
      "\n",
      "ğŸ” éªŒè¯ä¸­...\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘| 87.9% Loss: 1.5487 | Acc: 48.8%\n",
      "\n",
      "  âœ… éªŒè¯å®Œæˆ (2.4ç§’)\n",
      "     éå†: 91 batches\n",
      "     æœ‰æ•ˆ: 91 batches\n",
      "     æ ·æœ¬: 726 ä¸ª (æ­£ç¡®: 111)\n",
      "     Loss: 1.5162\n",
      "     å‡†ç¡®ç‡: 15.29% (ç±»åˆ«ç»Ÿè®¡)\n",
      "     âš ï¸  Batchå¹³å‡: 50.27% (å¯èƒ½ä¸å‡†ç¡®)\n",
      "     å¹³è¡¡å‡†ç¡®ç‡: 11.52%\n",
      "\n",
      "\n",
      "  â±ï¸  æœ¬è½®: 0.4min | å·²ç”¨: 1.5min | å‰©ä½™: 4.2min\n",
      "  ğŸ“… é¢„è®¡å®Œæˆ: 10:59:12\n",
      "\n",
      "======================================================================\n",
      "ğŸ“… Epoch [5/15]\n",
      "======================================================================\n",
      "\n",
      "ğŸ”¥ è®­ç»ƒä¸­...\n",
      "  â³ ç¬¬ä¸€ä¸ªbatch... âœ“ (0.0ç§’)\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 13.7% Loss: 1.5267 | Acc: 45.0% | 18.4it/s | ETA: 17s\n",
      "  ğŸ“Š [50/364] Loss: 1.5267 | Acc: 45.00% | 18.4 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 27.5% Loss: 1.5683 | Acc: 45.5% | 18.6it/s | ETA: 14s\n",
      "  ğŸ“Š [100/364] Loss: 1.5683 | Acc: 45.50% | 18.6 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 41.2% Loss: 1.5652 | Acc: 46.4% | 18.6it/s | ETA: 11s\n",
      "  ğŸ“Š [150/364] Loss: 1.5652 | Acc: 46.42% | 18.6 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 54.9% Loss: 1.5431 | Acc: 47.4% | 18.5it/s | ETA: 8ss\n",
      "  ğŸ“Š [200/364] Loss: 1.5431 | Acc: 47.44% | 18.5 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 68.7% Loss: 1.5450 | Acc: 47.3% | 18.3it/s | ETA: 6s\n",
      "  ğŸ“Š [250/364] Loss: 1.5450 | Acc: 47.30% | 18.3 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 82.4% Loss: 1.5298 | Acc: 47.7% | 18.1it/s | ETA: 3s\n",
      "  ğŸ“Š [300/364] Loss: 1.5298 | Acc: 47.67% | 18.1 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘| 96.2% Loss: 1.5233 | Acc: 47.5% | 17.9it/s | ETA: 0s\n",
      "  ğŸ“Š [350/364] Loss: 1.5233 | Acc: 47.46% | 17.8 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘| 98.9% Loss: 1.5253 | Acc: 47.2% | 17.8it/s | ETA: 0s\n",
      "\n",
      "  âœ… è®­ç»ƒå®Œæˆ (20.4ç§’)\n",
      "     éå†: 364 batches\n",
      "     æœ‰æ•ˆ: 364 batches\n",
      "     Loss: 1.5211 | Acc: 47.42%\n",
      "\n",
      "ğŸ” éªŒè¯ä¸­...\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘| 87.9% Loss: 1.4652 | Acc: 50.6%\n",
      "\n",
      "  âœ… éªŒè¯å®Œæˆ (2.5ç§’)\n",
      "     éå†: 91 batches\n",
      "     æœ‰æ•ˆ: 91 batches\n",
      "     æ ·æœ¬: 726 ä¸ª (æ­£ç¡®: 114)\n",
      "     Loss: 1.4433\n",
      "     å‡†ç¡®ç‡: 15.70% (ç±»åˆ«ç»Ÿè®¡)\n",
      "     âš ï¸  Batchå¹³å‡: 51.24% (å¯èƒ½ä¸å‡†ç¡®)\n",
      "     å¹³è¡¡å‡†ç¡®ç‡: 11.82%\n",
      "\n",
      "\n",
      "  ğŸ“Š å„ç±»åˆ«å‡†ç¡®ç‡:\n",
      "     Bacterial_spot              :  14.4% (13/90)\n",
      "     Early_blight                :   2.0% (1/51)\n",
      "     Late_blight                 :   7.1% (6/84)\n",
      "     Leaf_Mold                   :  10.7% (3/28)\n",
      "     Septoria_leaf_spot          :  10.3% (8/78)\n",
      "     Spider_mites                :  14.1% (9/64)\n",
      "     Target_Spot                 :  11.5% (7/61)\n",
      "     Yellow_Leaf_Curl_Virus      :  29.8% (61/205)\n",
      "     Tomato_mosaic_virus         :   9.1% (1/11)\n",
      "     Healthy                     :   9.3% (5/54)\n",
      "\n",
      "  â„¹ï¸  å‡†ç¡®ç‡éªŒè¯:\n",
      "     å„ç±»æ­£ç¡®æ•°æ€»å’Œ: 114\n",
      "     å„ç±»æ ·æœ¬æ•°æ€»å’Œ: 726\n",
      "     æ‰‹åŠ¨è®¡ç®—å‡†ç¡®ç‡: 114/726 = 15.70%\n",
      "\n",
      "  â±ï¸  æœ¬è½®: 0.4min | å·²ç”¨: 1.9min | å‰©ä½™: 3.8min\n",
      "  ğŸ“… é¢„è®¡å®Œæˆ: 10:59:13\n",
      "\n",
      "======================================================================\n",
      "ğŸ“… Epoch [6/15]\n",
      "======================================================================\n",
      "\n",
      "ğŸ”¥ è®­ç»ƒä¸­...\n",
      "  â³ ç¬¬ä¸€ä¸ªbatch... âœ“ (0.0ç§’)\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 13.7% Loss: 1.5454 | Acc: 47.2% | 18.5it/s | ETA: 16s\n",
      "  ğŸ“Š [50/364] Loss: 1.5454 | Acc: 47.25% | 18.5 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 27.5% Loss: 1.4477 | Acc: 49.1% | 18.5it/s | ETA: 14s\n",
      "  ğŸ“Š [100/364] Loss: 1.4477 | Acc: 49.12% | 18.5 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 41.2% Loss: 1.4911 | Acc: 48.0% | 18.3it/s | ETA: 11s\n",
      "  ğŸ“Š [150/364] Loss: 1.4911 | Acc: 48.00% | 18.3 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 54.9% Loss: 1.5021 | Acc: 47.6% | 18.2it/s | ETA: 9ss\n",
      "  ğŸ“Š [200/364] Loss: 1.5021 | Acc: 47.56% | 18.2 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 68.7% Loss: 1.5314 | Acc: 47.0% | 18.1it/s | ETA: 6s\n",
      "  ğŸ“Š [250/364] Loss: 1.5314 | Acc: 47.00% | 18.1 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 82.4% Loss: 1.5774 | Acc: 45.2% | 18.1it/s | ETA: 3s\n",
      "  ğŸ“Š [300/364] Loss: 1.5774 | Acc: 45.21% | 18.1 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘| 96.2% Loss: 1.5772 | Acc: 45.3% | 18.1it/s | ETA: 0s\n",
      "  ğŸ“Š [350/364] Loss: 1.5772 | Acc: 45.32% | 18.1 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘| 98.9% Loss: 1.5841 | Acc: 45.1% | 18.1it/s | ETA: 0s\n",
      "\n",
      "  âœ… è®­ç»ƒå®Œæˆ (20.1ç§’)\n",
      "     éå†: 364 batches\n",
      "     æœ‰æ•ˆ: 364 batches\n",
      "     Loss: 1.5798 | Acc: 45.43%\n",
      "\n",
      "ğŸ” éªŒè¯ä¸­...\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘| 87.9% Loss: 1.8734 | Acc: 39.7%\n",
      "\n",
      "  âœ… éªŒè¯å®Œæˆ (2.4ç§’)\n",
      "     éå†: 91 batches\n",
      "     æœ‰æ•ˆ: 91 batches\n",
      "     æ ·æœ¬: 726 ä¸ª (æ­£ç¡®: 114)\n",
      "     Loss: 1.8655\n",
      "     å‡†ç¡®ç‡: 15.70% (ç±»åˆ«ç»Ÿè®¡)\n",
      "     âš ï¸  Batchå¹³å‡: 39.65% (å¯èƒ½ä¸å‡†ç¡®)\n",
      "     å¹³è¡¡å‡†ç¡®ç‡: 11.82%\n",
      "\n",
      "\n",
      "  â±ï¸  æœ¬è½®: 0.4min | å·²ç”¨: 2.3min | å‰©ä½™: 3.4min\n",
      "  ğŸ“… é¢„è®¡å®Œæˆ: 10:59:12\n",
      "\n",
      "======================================================================\n",
      "ğŸ“… Epoch [7/15]\n",
      "======================================================================\n",
      "\n",
      "ğŸ”¥ è®­ç»ƒä¸­...\n",
      "  â³ ç¬¬ä¸€ä¸ªbatch... âœ“ (0.0ç§’)\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 13.7% Loss: 1.5869 | Acc: 45.5% | 18.3it/s | ETA: 17s\n",
      "  ğŸ“Š [50/364] Loss: 1.5869 | Acc: 45.50% | 18.3 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 27.5% Loss: 1.5725 | Acc: 45.8% | 18.1it/s | ETA: 14s\n",
      "  ğŸ“Š [100/364] Loss: 1.5725 | Acc: 45.75% | 18.1 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 41.2% Loss: 1.6449 | Acc: 43.6% | 18.0it/s | ETA: 11s\n",
      "  ğŸ“Š [150/364] Loss: 1.6449 | Acc: 43.58% | 18.0 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 54.9% Loss: 1.7087 | Acc: 41.6% | 18.0it/s | ETA: 9ss\n",
      "  ğŸ“Š [200/364] Loss: 1.7087 | Acc: 41.56% | 18.0 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 68.7% Loss: 1.7375 | Acc: 40.5% | 18.0it/s | ETA: 6s\n",
      "  ğŸ“Š [250/364] Loss: 1.7375 | Acc: 40.50% | 18.0 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 82.4% Loss: 1.7712 | Acc: 38.8% | 18.1it/s | ETA: 3s\n",
      "  ğŸ“Š [300/364] Loss: 1.7712 | Acc: 38.83% | 18.1 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘| 96.2% Loss: 1.7787 | Acc: 38.5% | 18.1it/s | ETA: 0s\n",
      "  ğŸ“Š [350/364] Loss: 1.7787 | Acc: 38.54% | 18.1 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘| 98.9% Loss: 1.7742 | Acc: 38.6% | 18.1it/s | ETA: 0s\n",
      "\n",
      "  âœ… è®­ç»ƒå®Œæˆ (20.1ç§’)\n",
      "     éå†: 364 batches\n",
      "     æœ‰æ•ˆ: 364 batches\n",
      "     Loss: 1.7741 | Acc: 38.56%\n",
      "\n",
      "ğŸ” éªŒè¯ä¸­...\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘| 87.9% Loss: 1.7585 | Acc: 38.3%\n",
      "\n",
      "  âœ… éªŒè¯å®Œæˆ (2.4ç§’)\n",
      "     éå†: 91 batches\n",
      "     æœ‰æ•ˆ: 91 batches\n",
      "     æ ·æœ¬: 726 ä¸ª (æ­£ç¡®: 115)\n",
      "     Loss: 1.7309\n",
      "     å‡†ç¡®ç‡: 15.84% (ç±»åˆ«ç»Ÿè®¡)\n",
      "     âš ï¸  Batchå¹³å‡: 38.42% (å¯èƒ½ä¸å‡†ç¡®)\n",
      "     å¹³è¡¡å‡†ç¡®ç‡: 11.87%\n",
      "\n",
      "\n",
      "  ğŸ‰ æ–°æœ€ä½³! å¹³è¡¡å‡†ç¡®ç‡: 11.87% (â†‘0.04%)\n",
      "\n",
      "  â±ï¸  æœ¬è½®: 0.4min | å·²ç”¨: 2.7min | å‰©ä½™: 3.0min\n",
      "  ğŸ“… é¢„è®¡å®Œæˆ: 10:59:12\n",
      "\n",
      "======================================================================\n",
      "ğŸ“… Epoch [8/15]\n",
      "======================================================================\n",
      "\n",
      "ğŸ”¥ è®­ç»ƒä¸­...\n",
      "  â³ ç¬¬ä¸€ä¸ªbatch... âœ“ (0.0ç§’)\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 13.7% Loss: 1.8261 | Acc: 37.2% | 17.9it/s | ETA: 17s\n",
      "  ğŸ“Š [50/364] Loss: 1.8261 | Acc: 37.25% | 17.9 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 27.5% Loss: 1.7649 | Acc: 40.8% | 18.1it/s | ETA: 14s\n",
      "  ğŸ“Š [100/364] Loss: 1.7649 | Acc: 40.75% | 18.1 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 41.2% Loss: 1.7580 | Acc: 41.3% | 18.1it/s | ETA: 11s\n",
      "  ğŸ“Š [150/364] Loss: 1.7580 | Acc: 41.33% | 18.1 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 54.9% Loss: 1.7563 | Acc: 40.6% | 18.1it/s | ETA: 9ss\n",
      "  ğŸ“Š [200/364] Loss: 1.7563 | Acc: 40.62% | 18.1 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 68.7% Loss: 1.7402 | Acc: 41.0% | 18.1it/s | ETA: 6s\n",
      "  ğŸ“Š [250/364] Loss: 1.7402 | Acc: 41.05% | 18.1 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 82.4% Loss: 1.7420 | Acc: 41.1% | 18.1it/s | ETA: 3s\n",
      "  ğŸ“Š [300/364] Loss: 1.7420 | Acc: 41.08% | 18.1 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘| 96.2% Loss: 1.7394 | Acc: 41.1% | 18.0it/s | ETA: 0s\n",
      "  ğŸ“Š [350/364] Loss: 1.7394 | Acc: 41.11% | 18.0 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘| 98.9% Loss: 1.7378 | Acc: 41.1% | 18.0it/s | ETA: 0s\n",
      "\n",
      "  âœ… è®­ç»ƒå®Œæˆ (20.2ç§’)\n",
      "     éå†: 364 batches\n",
      "     æœ‰æ•ˆ: 364 batches\n",
      "     Loss: 1.7404 | Acc: 40.93%\n",
      "\n",
      "ğŸ” éªŒè¯ä¸­...\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘| 87.9% Loss: 1.6997 | Acc: 37.3%\n",
      "\n",
      "  âœ… éªŒè¯å®Œæˆ (2.5ç§’)\n",
      "     éå†: 91 batches\n",
      "     æœ‰æ•ˆ: 91 batches\n",
      "     æ ·æœ¬: 726 ä¸ª (æ­£ç¡®: 113)\n",
      "     Loss: 1.6904\n",
      "     å‡†ç¡®ç‡: 15.56% (ç±»åˆ«ç»Ÿè®¡)\n",
      "     âš ï¸  Batchå¹³å‡: 37.91% (å¯èƒ½ä¸å‡†ç¡®)\n",
      "     å¹³è¡¡å‡†ç¡®ç‡: 11.80%\n",
      "\n",
      "\n",
      "  â±ï¸  æœ¬è½®: 0.4min | å·²ç”¨: 3.0min | å‰©ä½™: 2.7min\n",
      "  ğŸ“… é¢„è®¡å®Œæˆ: 10:59:12\n",
      "\n",
      "======================================================================\n",
      "ğŸ“… Epoch [9/15]\n",
      "======================================================================\n",
      "\n",
      "ğŸ”¥ è®­ç»ƒä¸­...\n",
      "  â³ ç¬¬ä¸€ä¸ªbatch... âœ“ (0.0ç§’)\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 13.7% Loss: 1.6834 | Acc: 47.0% | 17.6it/s | ETA: 17s\n",
      "  ğŸ“Š [50/364] Loss: 1.6834 | Acc: 47.00% | 17.6 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 27.5% Loss: 1.6792 | Acc: 45.5% | 17.8it/s | ETA: 14s\n",
      "  ğŸ“Š [100/364] Loss: 1.6792 | Acc: 45.50% | 17.8 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 41.2% Loss: 1.7072 | Acc: 44.2% | 18.0it/s | ETA: 11s\n",
      "  ğŸ“Š [150/364] Loss: 1.7072 | Acc: 44.25% | 18.0 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 54.9% Loss: 1.6960 | Acc: 43.4% | 18.1it/s | ETA: 9ss\n",
      "  ğŸ“Š [200/364] Loss: 1.6960 | Acc: 43.38% | 18.1 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 68.7% Loss: 1.6746 | Acc: 43.9% | 18.1it/s | ETA: 6s\n",
      "  ğŸ“Š [250/364] Loss: 1.6746 | Acc: 43.85% | 18.1 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 82.4% Loss: 1.6634 | Acc: 44.1% | 18.0it/s | ETA: 3s\n",
      "  ğŸ“Š [300/364] Loss: 1.6634 | Acc: 44.08% | 18.0 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘| 96.2% Loss: 1.6518 | Acc: 44.6% | 18.0it/s | ETA: 0s\n",
      "  ğŸ“Š [350/364] Loss: 1.6518 | Acc: 44.61% | 18.0 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘| 98.9% Loss: 1.6412 | Acc: 45.0% | 18.0it/s | ETA: 0s\n",
      "\n",
      "  âœ… è®­ç»ƒå®Œæˆ (20.2ç§’)\n",
      "     éå†: 364 batches\n",
      "     æœ‰æ•ˆ: 364 batches\n",
      "     Loss: 1.6418 | Acc: 44.95%\n",
      "\n",
      "ğŸ” éªŒè¯ä¸­...\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘| 87.9% Loss: 1.5325 | Acc: 51.1%\n",
      "\n",
      "  âœ… éªŒè¯å®Œæˆ (2.5ç§’)\n",
      "     éå†: 91 batches\n",
      "     æœ‰æ•ˆ: 91 batches\n",
      "     æ ·æœ¬: 726 ä¸ª (æ­£ç¡®: 112)\n",
      "     Loss: 1.5099\n",
      "     å‡†ç¡®ç‡: 15.43% (ç±»åˆ«ç»Ÿè®¡)\n",
      "     âš ï¸  Batchå¹³å‡: 52.06% (å¯èƒ½ä¸å‡†ç¡®)\n",
      "     å¹³è¡¡å‡†ç¡®ç‡: 11.55%\n",
      "\n",
      "\n",
      "  â±ï¸  æœ¬è½®: 0.4min | å·²ç”¨: 3.4min | å‰©ä½™: 2.3min\n",
      "  ğŸ“… é¢„è®¡å®Œæˆ: 10:59:12\n",
      "\n",
      "======================================================================\n",
      "ğŸ“… Epoch [10/15]\n",
      "======================================================================\n",
      "\n",
      "ğŸ”¥ è®­ç»ƒä¸­...\n",
      "  â³ ç¬¬ä¸€ä¸ªbatch... âœ“ (0.0ç§’)\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 13.7% Loss: 1.5317 | Acc: 47.5% | 18.1it/s | ETA: 17s\n",
      "  ğŸ“Š [50/364] Loss: 1.5317 | Acc: 47.50% | 18.1 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 27.5% Loss: 1.5230 | Acc: 48.1% | 17.9it/s | ETA: 14s\n",
      "  ğŸ“Š [100/364] Loss: 1.5230 | Acc: 48.12% | 17.9 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 41.2% Loss: 1.5029 | Acc: 49.2% | 17.9it/s | ETA: 11s\n",
      "  ğŸ“Š [150/364] Loss: 1.5029 | Acc: 49.25% | 17.9 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 54.9% Loss: 1.4945 | Acc: 49.6% | 17.8it/s | ETA: 9ss\n",
      "  ğŸ“Š [200/364] Loss: 1.4945 | Acc: 49.56% | 17.8 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 68.7% Loss: 1.4950 | Acc: 49.7% | 17.7it/s | ETA: 6s\n",
      "  ğŸ“Š [250/364] Loss: 1.4950 | Acc: 49.70% | 17.7 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 82.4% Loss: 1.5049 | Acc: 49.6% | 17.7it/s | ETA: 3s\n",
      "  ğŸ“Š [300/364] Loss: 1.5049 | Acc: 49.58% | 17.7 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘| 96.2% Loss: 1.5084 | Acc: 49.0% | 17.8it/s | ETA: 0s\n",
      "  ğŸ“Š [350/364] Loss: 1.5084 | Acc: 49.04% | 17.8 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘| 98.9% Loss: 1.5106 | Acc: 49.0% | 17.7it/s | ETA: 0s\n",
      "\n",
      "  âœ… è®­ç»ƒå®Œæˆ (20.5ç§’)\n",
      "     éå†: 364 batches\n",
      "     æœ‰æ•ˆ: 364 batches\n",
      "     Loss: 1.5115 | Acc: 48.76%\n",
      "\n",
      "ğŸ” éªŒè¯ä¸­...\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘| 87.9% Loss: 1.4803 | Acc: 49.8%\n",
      "\n",
      "  âœ… éªŒè¯å®Œæˆ (2.5ç§’)\n",
      "     éå†: 91 batches\n",
      "     æœ‰æ•ˆ: 91 batches\n",
      "     æ ·æœ¬: 726 ä¸ª (æ­£ç¡®: 113)\n",
      "     Loss: 1.4606\n",
      "     å‡†ç¡®ç‡: 15.56% (ç±»åˆ«ç»Ÿè®¡)\n",
      "     âš ï¸  Batchå¹³å‡: 50.41% (å¯èƒ½ä¸å‡†ç¡®)\n",
      "     å¹³è¡¡å‡†ç¡®ç‡: 11.77%\n",
      "\n",
      "\n",
      "  ğŸ“Š å„ç±»åˆ«å‡†ç¡®ç‡:\n",
      "     Bacterial_spot              :  13.3% (12/90)\n",
      "     Early_blight                :   1.9% (1/52)\n",
      "     Late_blight                 :   7.1% (6/85)\n",
      "     Leaf_Mold                   :  10.3% (3/29)\n",
      "     Septoria_leaf_spot          :  11.7% (9/77)\n",
      "     Spider_mites                :  13.8% (9/65)\n",
      "     Target_Spot                 :  11.5% (7/61)\n",
      "     Yellow_Leaf_Curl_Virus      :  29.7% (60/202)\n",
      "     Tomato_mosaic_virus         :   9.1% (1/11)\n",
      "     Healthy                     :   9.3% (5/54)\n",
      "\n",
      "  â„¹ï¸  å‡†ç¡®ç‡éªŒè¯:\n",
      "     å„ç±»æ­£ç¡®æ•°æ€»å’Œ: 113\n",
      "     å„ç±»æ ·æœ¬æ•°æ€»å’Œ: 726\n",
      "     æ‰‹åŠ¨è®¡ç®—å‡†ç¡®ç‡: 113/726 = 15.56%\n",
      "\n",
      "  â±ï¸  æœ¬è½®: 0.4min | å·²ç”¨: 3.8min | å‰©ä½™: 1.9min\n",
      "  ğŸ“… é¢„è®¡å®Œæˆ: 10:59:13\n",
      "\n",
      "======================================================================\n",
      "ğŸ“… Epoch [11/15]\n",
      "======================================================================\n",
      "\n",
      "ğŸ”¥ è®­ç»ƒä¸­...\n",
      "  â³ ç¬¬ä¸€ä¸ªbatch... âœ“ (0.0ç§’)\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 13.7% Loss: 1.3599 | Acc: 54.8% | 18.0it/s | ETA: 17s\n",
      "  ğŸ“Š [50/364] Loss: 1.3599 | Acc: 54.75% | 18.0 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 27.5% Loss: 1.3891 | Acc: 52.2% | 17.6it/s | ETA: 14s\n",
      "  ğŸ“Š [100/364] Loss: 1.3891 | Acc: 52.25% | 17.6 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 41.2% Loss: 1.4274 | Acc: 50.5% | 17.7it/s | ETA: 12s\n",
      "  ğŸ“Š [150/364] Loss: 1.4274 | Acc: 50.50% | 17.7 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 54.9% Loss: 1.4281 | Acc: 50.9% | 17.7it/s | ETA: 9ss\n",
      "  ğŸ“Š [200/364] Loss: 1.4281 | Acc: 50.88% | 17.7 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 68.7% Loss: 1.4169 | Acc: 51.5% | 17.8it/s | ETA: 6s\n",
      "  ğŸ“Š [250/364] Loss: 1.4169 | Acc: 51.55% | 17.8 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 82.4% Loss: 1.4287 | Acc: 51.5% | 17.7it/s | ETA: 3s\n",
      "  ğŸ“Š [300/364] Loss: 1.4287 | Acc: 51.46% | 17.7 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘| 96.2% Loss: 1.4325 | Acc: 51.2% | 17.8it/s | ETA: 0s\n",
      "  ğŸ“Š [350/364] Loss: 1.4325 | Acc: 51.18% | 17.8 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘| 98.9% Loss: 1.4353 | Acc: 51.2% | 17.8it/s | ETA: 0s\n",
      "\n",
      "  âœ… è®­ç»ƒå®Œæˆ (20.5ç§’)\n",
      "     éå†: 364 batches\n",
      "     æœ‰æ•ˆ: 364 batches\n",
      "     Loss: 1.4321 | Acc: 51.30%\n",
      "\n",
      "ğŸ” éªŒè¯ä¸­...\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘| 87.9% Loss: 1.5880 | Acc: 43.9%\n",
      "\n",
      "  âœ… éªŒè¯å®Œæˆ (2.5ç§’)\n",
      "     éå†: 91 batches\n",
      "     æœ‰æ•ˆ: 91 batches\n",
      "     æ ·æœ¬: 726 ä¸ª (æ­£ç¡®: 114)\n",
      "     Loss: 1.5594\n",
      "     å‡†ç¡®ç‡: 15.70% (ç±»åˆ«ç»Ÿè®¡)\n",
      "     âš ï¸  Batchå¹³å‡: 45.28% (å¯èƒ½ä¸å‡†ç¡®)\n",
      "     å¹³è¡¡å‡†ç¡®ç‡: 11.90%\n",
      "\n",
      "\n",
      "  ğŸ‰ æ–°æœ€ä½³! å¹³è¡¡å‡†ç¡®ç‡: 11.90% (â†‘0.04%)\n",
      "\n",
      "  â±ï¸  æœ¬è½®: 0.4min | å·²ç”¨: 4.2min | å‰©ä½™: 1.5min\n",
      "  ğŸ“… é¢„è®¡å®Œæˆ: 10:59:13\n",
      "\n",
      "======================================================================\n",
      "ğŸ“… Epoch [12/15]\n",
      "======================================================================\n",
      "\n",
      "ğŸ”¥ è®­ç»ƒä¸­...\n",
      "  â³ ç¬¬ä¸€ä¸ªbatch... âœ“ (0.0ç§’)\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 13.7% Loss: 1.3134 | Acc: 56.8% | 17.4it/s | ETA: 18s\n",
      "  ğŸ“Š [50/364] Loss: 1.3134 | Acc: 56.75% | 17.4 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 27.5% Loss: 1.3505 | Acc: 54.0% | 17.5it/s | ETA: 15s\n",
      "  ğŸ“Š [100/364] Loss: 1.3505 | Acc: 54.00% | 17.5 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 41.2% Loss: 1.3550 | Acc: 54.1% | 17.5it/s | ETA: 12s\n",
      "  ğŸ“Š [150/364] Loss: 1.3550 | Acc: 54.08% | 17.5 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 54.9% Loss: 1.3928 | Acc: 52.9% | 17.5it/s | ETA: 9ss\n",
      "  ğŸ“Š [200/364] Loss: 1.3928 | Acc: 52.94% | 17.5 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 68.7% Loss: 1.3875 | Acc: 52.8% | 17.5it/s | ETA: 6s\n",
      "  ğŸ“Š [250/364] Loss: 1.3875 | Acc: 52.75% | 17.5 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 82.4% Loss: 1.3944 | Acc: 52.6% | 17.5it/s | ETA: 3s\n",
      "  ğŸ“Š [300/364] Loss: 1.3944 | Acc: 52.58% | 17.5 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘| 96.2% Loss: 1.4033 | Acc: 52.5% | 17.5it/s | ETA: 0s\n",
      "  ğŸ“Š [350/364] Loss: 1.4033 | Acc: 52.50% | 17.5 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘| 98.9% Loss: 1.3994 | Acc: 52.7% | 17.5it/s | ETA: 0s\n",
      "\n",
      "  âœ… è®­ç»ƒå®Œæˆ (20.7ç§’)\n",
      "     éå†: 364 batches\n",
      "     æœ‰æ•ˆ: 364 batches\n",
      "     Loss: 1.4091 | Acc: 52.54%\n",
      "\n",
      "ğŸ” éªŒè¯ä¸­...\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘| 87.9% Loss: 1.5088 | Acc: 47.0%\n",
      "\n",
      "  âœ… éªŒè¯å®Œæˆ (2.5ç§’)\n",
      "     éå†: 91 batches\n",
      "     æœ‰æ•ˆ: 91 batches\n",
      "     æ ·æœ¬: 726 ä¸ª (æ­£ç¡®: 114)\n",
      "     Loss: 1.4619\n",
      "     å‡†ç¡®ç‡: 15.70% (ç±»åˆ«ç»Ÿè®¡)\n",
      "     âš ï¸  Batchå¹³å‡: 49.18% (å¯èƒ½ä¸å‡†ç¡®)\n",
      "     å¹³è¡¡å‡†ç¡®ç‡: 11.85%\n",
      "\n",
      "\n",
      "  â±ï¸  æœ¬è½®: 0.4min | å·²ç”¨: 4.6min | å‰©ä½™: 1.1min\n",
      "  ğŸ“… é¢„è®¡å®Œæˆ: 10:59:14\n",
      "\n",
      "======================================================================\n",
      "ğŸ“… Epoch [13/15]\n",
      "======================================================================\n",
      "\n",
      "ğŸ”¥ è®­ç»ƒä¸­...\n",
      "  â³ ç¬¬ä¸€ä¸ªbatch... âœ“ (0.0ç§’)\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 13.7% Loss: 1.3247 | Acc: 56.0% | 17.8it/s | ETA: 17s\n",
      "  ğŸ“Š [50/364] Loss: 1.3247 | Acc: 56.00% | 17.8 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 27.5% Loss: 1.3581 | Acc: 54.1% | 17.7it/s | ETA: 14s\n",
      "  ğŸ“Š [100/364] Loss: 1.3581 | Acc: 54.12% | 17.7 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 41.2% Loss: 1.3231 | Acc: 55.9% | 17.7it/s | ETA: 12s\n",
      "  ğŸ“Š [150/364] Loss: 1.3231 | Acc: 55.92% | 17.7 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 54.9% Loss: 1.3337 | Acc: 55.3% | 17.8it/s | ETA: 9ss\n",
      "  ğŸ“Š [200/364] Loss: 1.3337 | Acc: 55.31% | 17.8 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 68.7% Loss: 1.3198 | Acc: 55.8% | 17.8it/s | ETA: 6s\n",
      "  ğŸ“Š [250/364] Loss: 1.3198 | Acc: 55.80% | 17.8 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 82.4% Loss: 1.3129 | Acc: 56.2% | 17.7it/s | ETA: 3s\n",
      "  ğŸ“Š [300/364] Loss: 1.3129 | Acc: 56.25% | 17.7 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘| 96.2% Loss: 1.3105 | Acc: 56.6% | 17.6it/s | ETA: 0s\n",
      "  ğŸ“Š [350/364] Loss: 1.3105 | Acc: 56.61% | 17.6 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘| 98.9% Loss: 1.3056 | Acc: 56.7% | 17.6it/s | ETA: 0s\n",
      "\n",
      "  âœ… è®­ç»ƒå®Œæˆ (20.7ç§’)\n",
      "     éå†: 364 batches\n",
      "     æœ‰æ•ˆ: 364 batches\n",
      "     Loss: 1.3072 | Acc: 56.66%\n",
      "\n",
      "ğŸ” éªŒè¯ä¸­...\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘| 87.9% Loss: 1.3961 | Acc: 52.0%\n",
      "\n",
      "  âœ… éªŒè¯å®Œæˆ (2.6ç§’)\n",
      "     éå†: 91 batches\n",
      "     æœ‰æ•ˆ: 91 batches\n",
      "     æ ·æœ¬: 726 ä¸ª (æ­£ç¡®: 112)\n",
      "     Loss: 1.3642\n",
      "     å‡†ç¡®ç‡: 15.43% (ç±»åˆ«ç»Ÿè®¡)\n",
      "     âš ï¸  Batchå¹³å‡: 53.39% (å¯èƒ½ä¸å‡†ç¡®)\n",
      "     å¹³è¡¡å‡†ç¡®ç‡: 11.71%\n",
      "\n",
      "\n",
      "  â±ï¸  æœ¬è½®: 0.4min | å·²ç”¨: 5.0min | å‰©ä½™: 0.8min\n",
      "  ğŸ“… é¢„è®¡å®Œæˆ: 10:59:14\n",
      "\n",
      "======================================================================\n",
      "ğŸ“… Epoch [14/15]\n",
      "======================================================================\n",
      "\n",
      "ğŸ”¥ è®­ç»ƒä¸­...\n",
      "  â³ ç¬¬ä¸€ä¸ªbatch... âœ“ (0.0ç§’)\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 13.7% Loss: 1.3031 | Acc: 56.5% | 17.9it/s | ETA: 17s\n",
      "  ğŸ“Š [50/364] Loss: 1.3031 | Acc: 56.50% | 17.9 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 27.5% Loss: 1.2963 | Acc: 56.2% | 17.8it/s | ETA: 14s\n",
      "  ğŸ“Š [100/364] Loss: 1.2963 | Acc: 56.25% | 17.8 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 41.2% Loss: 1.2900 | Acc: 56.1% | 17.8it/s | ETA: 12s\n",
      "  ğŸ“Š [150/364] Loss: 1.2900 | Acc: 56.08% | 17.8 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 54.9% Loss: 1.2976 | Acc: 56.0% | 17.8it/s | ETA: 9ss\n",
      "  ğŸ“Š [200/364] Loss: 1.2976 | Acc: 56.00% | 17.8 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 68.7% Loss: 1.2824 | Acc: 56.7% | 17.8it/s | ETA: 6s\n",
      "  ğŸ“Š [250/364] Loss: 1.2824 | Acc: 56.70% | 17.8 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 82.4% Loss: 1.2969 | Acc: 56.1% | 17.7it/s | ETA: 3s\n",
      "  ğŸ“Š [300/364] Loss: 1.2969 | Acc: 56.12% | 17.7 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘| 96.2% Loss: 1.3077 | Acc: 55.7% | 17.7it/s | ETA: 0s\n",
      "  ğŸ“Š [350/364] Loss: 1.3077 | Acc: 55.68% | 17.7 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘| 98.9% Loss: 1.3068 | Acc: 55.8% | 17.7it/s | ETA: 0s\n",
      "\n",
      "  âœ… è®­ç»ƒå®Œæˆ (20.6ç§’)\n",
      "     éå†: 364 batches\n",
      "     æœ‰æ•ˆ: 364 batches\n",
      "     Loss: 1.3102 | Acc: 55.49%\n",
      "\n",
      "ğŸ” éªŒè¯ä¸­...\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘| 87.9% Loss: 1.4546 | Acc: 49.7%\n",
      "\n",
      "  âœ… éªŒè¯å®Œæˆ (2.6ç§’)\n",
      "     éå†: 91 batches\n",
      "     æœ‰æ•ˆ: 91 batches\n",
      "     æ ·æœ¬: 726 ä¸ª (æ­£ç¡®: 113)\n",
      "     Loss: 1.4181\n",
      "     å‡†ç¡®ç‡: 15.56% (ç±»åˆ«ç»Ÿè®¡)\n",
      "     âš ï¸  Batchå¹³å‡: 50.55% (å¯èƒ½ä¸å‡†ç¡®)\n",
      "     å¹³è¡¡å‡†ç¡®ç‡: 11.78%\n",
      "\n",
      "\n",
      "  â±ï¸  æœ¬è½®: 0.4min | å·²ç”¨: 5.3min | å‰©ä½™: 0.4min\n",
      "  ğŸ“… é¢„è®¡å®Œæˆ: 10:59:15\n",
      "\n",
      "======================================================================\n",
      "ğŸ“… Epoch [15/15]\n",
      "======================================================================\n",
      "\n",
      "ğŸ”¥ è®­ç»ƒä¸­...\n",
      "  â³ ç¬¬ä¸€ä¸ªbatch... âœ“ (0.0ç§’)\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 13.7% Loss: 1.3056 | Acc: 55.5% | 17.2it/s | ETA: 18s\n",
      "  ğŸ“Š [50/364] Loss: 1.3056 | Acc: 55.50% | 17.2 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 27.5% Loss: 1.3036 | Acc: 55.8% | 17.2it/s | ETA: 15s\n",
      "  ğŸ“Š [100/364] Loss: 1.3036 | Acc: 55.75% | 17.2 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 41.2% Loss: 1.2929 | Acc: 55.6% | 17.4it/s | ETA: 12s\n",
      "  ğŸ“Š [150/364] Loss: 1.2929 | Acc: 55.58% | 17.4 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 54.9% Loss: 1.3187 | Acc: 55.5% | 17.5it/s | ETA: 9ss\n",
      "  ğŸ“Š [200/364] Loss: 1.3187 | Acc: 55.50% | 17.5 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 68.7% Loss: 1.3458 | Acc: 54.4% | 17.6it/s | ETA: 6s\n",
      "  ğŸ“Š [250/364] Loss: 1.3458 | Acc: 54.35% | 17.6 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 82.4% Loss: 1.3367 | Acc: 54.8% | 17.7it/s | ETA: 3s\n",
      "  ğŸ“Š [300/364] Loss: 1.3367 | Acc: 54.83% | 17.7 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘| 96.2% Loss: 1.3573 | Acc: 54.2% | 17.7it/s | ETA: 0s\n",
      "  ğŸ“Š [350/364] Loss: 1.3573 | Acc: 54.18% | 17.7 batch/s\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘| 98.9% Loss: 1.3568 | Acc: 54.2% | 17.7it/s | ETA: 0s\n",
      "\n",
      "  âœ… è®­ç»ƒå®Œæˆ (20.5ç§’)\n",
      "     éå†: 364 batches\n",
      "     æœ‰æ•ˆ: 364 batches\n",
      "     Loss: 1.3508 | Acc: 54.40%\n",
      "\n",
      "ğŸ” éªŒè¯ä¸­...\n",
      "  è¿›åº¦ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘| 87.9% Loss: 1.4153 | Acc: 52.2%\n",
      "\n",
      "  âœ… éªŒè¯å®Œæˆ (2.5ç§’)\n",
      "     éå†: 91 batches\n",
      "     æœ‰æ•ˆ: 91 batches\n",
      "     æ ·æœ¬: 726 ä¸ª (æ­£ç¡®: 112)\n",
      "     Loss: 1.3900\n",
      "     å‡†ç¡®ç‡: 15.43% (ç±»åˆ«ç»Ÿè®¡)\n",
      "     âš ï¸  Batchå¹³å‡: 52.93% (å¯èƒ½ä¸å‡†ç¡®)\n",
      "     å¹³è¡¡å‡†ç¡®ç‡: 11.67%\n",
      "\n",
      "\n",
      "  ğŸ“Š å„ç±»åˆ«å‡†ç¡®ç‡:\n",
      "     Bacterial_spot              :  13.5% (12/89)\n",
      "     Early_blight                :   2.0% (1/51)\n",
      "     Late_blight                 :   5.9% (5/85)\n",
      "     Leaf_Mold                   :  10.7% (3/28)\n",
      "     Septoria_leaf_spot          :  11.5% (9/78)\n",
      "     Spider_mites                :  14.1% (9/64)\n",
      "     Target_Spot                 :  11.5% (7/61)\n",
      "     Yellow_Leaf_Curl_Virus      :  29.4% (60/204)\n",
      "     Tomato_mosaic_virus         :   9.1% (1/11)\n",
      "     Healthy                     :   9.1% (5/55)\n",
      "\n",
      "  â„¹ï¸  å‡†ç¡®ç‡éªŒè¯:\n",
      "     å„ç±»æ­£ç¡®æ•°æ€»å’Œ: 112\n",
      "     å„ç±»æ ·æœ¬æ•°æ€»å’Œ: 726\n",
      "     æ‰‹åŠ¨è®¡ç®—å‡†ç¡®ç‡: 112/726 = 15.43%\n",
      "\n",
      "  â±ï¸  æœ¬è½®: 0.4min | å·²ç”¨: 5.7min | å‰©ä½™: 0.0min\n",
      "  ğŸ“… é¢„è®¡å®Œæˆ: 10:59:15\n",
      "\n",
      "======================================================================\n",
      "ğŸŠ è®­ç»ƒå®Œæˆ! æ€»è€—æ—¶: 5.7åˆ†é’Ÿ\n",
      "======================================================================\n",
      "æœ€ä½³å‡†ç¡®ç‡: 15.70%\n",
      "æœ€ä½³å¹³è¡¡å‡†ç¡®ç‡: 11.90%\n",
      "æ¨¡å‹ä¿å­˜: /home/jittor/SCC_Model/ViT/checkpoints/best_model.pkl\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import jittor as jt\n",
    "from jittor import nn\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "current_dir = os.path.abspath('.')\n",
    "project_root = os.path.dirname(current_dir)\n",
    "\n",
    "if project_root in sys.path:\n",
    "    sys.path.remove(project_root)\n",
    "\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "from data_loader import get_dataloader, CLASS_NAMES\n",
    "from models.vit_model import Visual_Transformer\n",
    "from config import Config\n",
    "\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    jt.set_global_seed(seed)\n",
    "\n",
    "\n",
    "def calculate_accuracy(outputs, labels):\n",
    "    preds = jt.argmax(outputs, dim=1)[0]\n",
    "    correct = jt.sum(preds == labels)\n",
    "    return float(correct) / labels.shape[0]\n",
    "\n",
    "\n",
    "def validate_labels(labels, num_classes):\n",
    "    \"\"\"å¿«é€Ÿæ ‡ç­¾éªŒè¯ï¼Œè¿”å› jittor bool array\"\"\"\n",
    "    labels_np = labels.numpy()\n",
    "    valid_mask = (labels_np >= 0) & (labels_np < num_classes)\n",
    "    return jt.array(valid_mask)\n",
    "\n",
    "\n",
    "def format_time(seconds):\n",
    "    return str(timedelta(seconds=int(seconds)))\n",
    "\n",
    "\n",
    "def print_progress_bar(current, total, prefix='', suffix='', length=40):\n",
    "    if total == 0:\n",
    "        return\n",
    "    percent = 100 * (current / float(total))\n",
    "    filled = int(length * current // total)\n",
    "    bar = 'â–ˆ' * filled + 'â–‘' * (length - filled)\n",
    "    print(f'\\r{prefix} |{bar}| {percent:.1f}% {suffix}', end='', flush=True)\n",
    "\n",
    "\n",
    "def train():\n",
    "    config = Config()\n",
    "    jt.flags.use_cuda = 1 if jt.has_cuda else 0\n",
    "    set_seed(42)\n",
    "    \n",
    "    # ========== é…ç½® ==========\n",
    "    EPOCHS = 15\n",
    "    BATCH_SIZE = 8\n",
    "    NUM_WORKERS = 0\n",
    "    TRAIN_SAMPLE_RATIO = 0.2\n",
    "    VAL_SAMPLE_RATIO = 0.2\n",
    "    PRINT_FREQ = 50\n",
    "    \n",
    "    data_root = os.path.join(project_root, 'tomato_yolo_dataset')\n",
    "    save_dir = os.path.join(project_root, 'checkpoints')\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ğŸš€ è®­ç»ƒé…ç½®\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"è®¾å¤‡: {'ğŸ® GPU' if jt.flags.use_cuda else 'ğŸ’» CPU'}\")\n",
    "    print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "    print(f\"è®­ç»ƒè½®æ•°: {EPOCHS}\")\n",
    "    print(f\"è®­ç»ƒé‡‡æ ·ç‡: {TRAIN_SAMPLE_RATIO*100:.0f}%\")\n",
    "    print(f\"éªŒè¯é‡‡æ ·ç‡: {VAL_SAMPLE_RATIO*100:.0f}%\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # ========== æ•°æ®åŠ è½½ ==========\n",
    "    print(\"ğŸ“¦ åŠ è½½æ•°æ®...\", flush=True)\n",
    "    \n",
    "    train_loader = get_dataloader(\n",
    "        root_dir=data_root,\n",
    "        mode='train',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        img_size=config.IMG_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        sample_ratio=TRAIN_SAMPLE_RATIO\n",
    "    )\n",
    "    \n",
    "    val_loader = get_dataloader(\n",
    "        root_dir=data_root,\n",
    "        mode='val',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        img_size=config.IMG_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        sample_ratio=VAL_SAMPLE_RATIO\n",
    "    )\n",
    "    \n",
    "    total_train_batches = None\n",
    "    total_val_batches = None\n",
    "    \n",
    "    print(f\"âœ“ æ•°æ®åŠ è½½å®Œæˆ\\n\")\n",
    "    \n",
    "    # ========== å¿«é€Ÿæ ‡ç­¾æ£€æŸ¥ ==========\n",
    "    print(\"ğŸ” æ£€æŸ¥æ•°æ®é›†æ ‡ç­¾ï¼ˆå‰10ä¸ªbatchï¼‰...\", flush=True)\n",
    "    check_count = 0\n",
    "    invalid_count = 0\n",
    "    check_batches = 0\n",
    "    for idx, (_, labels) in enumerate(train_loader):\n",
    "        if idx >= 10:\n",
    "            break\n",
    "        labels_np = labels.numpy()\n",
    "        check_count += len(labels_np)\n",
    "        invalid_count += ((labels_np < 0) | (labels_np >= config.NUM_CLASSES)).sum()\n",
    "        check_batches += 1\n",
    "    \n",
    "    if invalid_count > 0:\n",
    "        print(f\"  âš ï¸  å‘ç° {invalid_count}/{check_count} ä¸ªå¼‚å¸¸æ ‡ç­¾ ({invalid_count/check_count*100:.1f}%)\")\n",
    "        print(f\"  è®­ç»ƒæ—¶ä¼šè‡ªåŠ¨è¿‡æ»¤\\n\")\n",
    "    else:\n",
    "        print(f\"  âœ“ æ ‡ç­¾æ­£å¸¸ (æ£€æŸ¥äº†{check_batches}ä¸ªbatch)\\n\")\n",
    "    \n",
    "    # ========== åˆ›å»ºæ¨¡å‹ ==========\n",
    "    print(\"ğŸ—ï¸  åˆ›å»ºæ¨¡å‹...\", flush=True)\n",
    "    \n",
    "    model = Visual_Transformer(\n",
    "        img_size=config.IMG_SIZE,\n",
    "        patch_size=config.PATCH_SIZE,\n",
    "        in_channels=config.IN_CHANNELS,\n",
    "        embed_dim=config.EMBED_DIM,\n",
    "        depth=config.NUM_LAYERS,\n",
    "        num_heads=config.NUM_HEADS,\n",
    "        dropout_rate=0.1,\n",
    "        hidden_dim=config.MLP_Hidden_Dim\n",
    "    )\n",
    "    \n",
    "    print(\"  æµ‹è¯•å‰å‘ä¼ æ’­...\", flush=True)\n",
    "    model.eval()\n",
    "    with jt.no_grad():\n",
    "        for imgs, lbls in train_loader:\n",
    "            valid_mask = validate_labels(lbls, config.NUM_CLASSES)\n",
    "            valid_count = int(jt.sum(valid_mask))\n",
    "            if valid_count > 0:\n",
    "                valid_imgs = imgs[valid_mask]\n",
    "                test_out = model(valid_imgs[:min(2, valid_count)])\n",
    "                print(f\"  âœ“ æµ‹è¯•é€šè¿‡: {test_out.shape}\\n\")\n",
    "                break\n",
    "    \n",
    "    # ========== ä¼˜åŒ–å™¨ ==========\n",
    "    optimizer = nn.Adam(model.parameters(), lr=config.LEARNING_RATE, weight_decay=1e-4)\n",
    "    \n",
    "    # ========== è®­ç»ƒå¾ªç¯ ==========\n",
    "    best_acc = 0.0\n",
    "    best_balanced_acc = 0.0\n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"ğŸ¯ å¼€å§‹è®­ç»ƒ ({time.strftime('%H:%M:%S')})\")\n",
    "    print(f\"{'='*70}\\n\", flush=True)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ğŸ“… Epoch [{epoch+1}/{EPOCHS}]\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # ========== è®­ç»ƒé˜¶æ®µ ==========\n",
    "        print(f\"\\nğŸ”¥ è®­ç»ƒä¸­...\", flush=True)\n",
    "        model.train()\n",
    "        \n",
    "        train_loss_sum = 0.0\n",
    "        train_acc_sum = 0.0\n",
    "        train_batches = 0\n",
    "        skipped = 0\n",
    "        actual_batch_count = 0\n",
    "        \n",
    "        train_start = time.time()\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            actual_batch_count = batch_idx + 1\n",
    "            \n",
    "            if batch_idx == 0:\n",
    "                print(f\"  â³ ç¬¬ä¸€ä¸ªbatch...\", end='', flush=True)\n",
    "                first_start = time.time()\n",
    "            \n",
    "            valid_mask = validate_labels(labels, config.NUM_CLASSES)\n",
    "            valid_count = int(jt.sum(valid_mask))\n",
    "            \n",
    "            if valid_count == 0:\n",
    "                skipped += 1\n",
    "                continue\n",
    "            \n",
    "            if valid_count < len(labels):\n",
    "                images = images[valid_mask]\n",
    "                labels = labels[valid_mask]\n",
    "            \n",
    "            outputs = model(images)\n",
    "            if jt.isnan(outputs).any():\n",
    "                skipped += 1\n",
    "                continue\n",
    "            \n",
    "            loss = nn.cross_entropy_loss(outputs, labels)\n",
    "            if jt.isnan(loss).any():\n",
    "                skipped += 1\n",
    "                continue\n",
    "            \n",
    "            optimizer.step(loss)\n",
    "            \n",
    "            train_loss_sum += float(loss)\n",
    "            train_acc_sum += calculate_accuracy(outputs, labels)\n",
    "            train_batches += 1\n",
    "            \n",
    "            if batch_idx == 0:\n",
    "                first_time = time.time() - first_start\n",
    "                print(f\" âœ“ ({first_time:.1f}ç§’)\", flush=True)\n",
    "            \n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                avg_loss = train_loss_sum / train_batches if train_batches > 0 else 0\n",
    "                avg_acc = train_acc_sum / train_batches if train_batches > 0 else 0\n",
    "                elapsed = time.time() - train_start\n",
    "                speed = (batch_idx + 1) / elapsed\n",
    "                \n",
    "                if total_train_batches is not None:\n",
    "                    eta = (total_train_batches - batch_idx - 1) / speed if speed > 0 else 0\n",
    "                    suffix = f\"Loss: {avg_loss:.4f} | Acc: {avg_acc*100:.1f}% | {speed:.1f}it/s | ETA: {int(eta)}s\"\n",
    "                    print_progress_bar(batch_idx + 1, total_train_batches, prefix='  è¿›åº¦', suffix=suffix)\n",
    "                else:\n",
    "                    suffix = f\"Loss: {avg_loss:.4f} | Acc: {avg_acc*100:.1f}% | {speed:.1f}it/s\"\n",
    "                    print(f'\\r  è¿›åº¦: {batch_idx+1} batches | {suffix}', end='', flush=True)\n",
    "            \n",
    "            if (batch_idx + 1) % PRINT_FREQ == 0:\n",
    "                avg_loss = train_loss_sum / train_batches if train_batches > 0 else 0\n",
    "                avg_acc = train_acc_sum / train_batches if train_batches > 0 else 0\n",
    "                elapsed = time.time() - train_start\n",
    "                speed = (batch_idx + 1) / elapsed\n",
    "                \n",
    "                if total_train_batches is not None:\n",
    "                    print(f\"\\n  ğŸ“Š [{batch_idx+1}/{total_train_batches}] \"\n",
    "                          f\"Loss: {avg_loss:.4f} | Acc: {avg_acc*100:.2f}% | \"\n",
    "                          f\"{speed:.1f} batch/s\", flush=True)\n",
    "                else:\n",
    "                    print(f\"\\n  ğŸ“Š [{batch_idx+1}] \"\n",
    "                          f\"Loss: {avg_loss:.4f} | Acc: {avg_acc*100:.2f}% | \"\n",
    "                          f\"{speed:.1f} batch/s\", flush=True)\n",
    "        \n",
    "        if total_train_batches is None:\n",
    "            total_train_batches = actual_batch_count\n",
    "            print(f\"\\n\\n  â„¹ï¸  æ£€æµ‹åˆ°è®­ç»ƒé›†å®é™…batchæ•°: {total_train_batches}\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        train_time = time.time() - train_start\n",
    "        avg_train_loss = train_loss_sum / train_batches if train_batches > 0 else 0\n",
    "        avg_train_acc = train_acc_sum / train_batches if train_batches > 0 else 0\n",
    "        \n",
    "        print(f\"\\n  âœ… è®­ç»ƒå®Œæˆ ({train_time:.1f}ç§’)\")\n",
    "        print(f\"     éå†: {actual_batch_count} batches\")\n",
    "        print(f\"     æœ‰æ•ˆ: {train_batches} batches\")\n",
    "        print(f\"     Loss: {avg_train_loss:.4f} | Acc: {avg_train_acc*100:.2f}%\")\n",
    "        if skipped > 0:\n",
    "            print(f\"     è·³è¿‡: {skipped} ä¸ªå¼‚å¸¸batch\")\n",
    "        print(flush=True)\n",
    "        \n",
    "        # ========== éªŒè¯é˜¶æ®µ ==========\n",
    "        print(f\"ğŸ” éªŒè¯ä¸­...\", flush=True)\n",
    "        model.eval()\n",
    "        \n",
    "        val_loss_sum = 0.0\n",
    "        val_acc_sum = 0.0\n",
    "        val_batches = 0\n",
    "        class_correct = np.zeros(config.NUM_CLASSES, dtype=np.int64)\n",
    "        class_total = np.zeros(config.NUM_CLASSES, dtype=np.int64)\n",
    "        val_skipped = 0\n",
    "        actual_val_batch_count = 0\n",
    "        \n",
    "        val_start = time.time()\n",
    "        \n",
    "        with jt.no_grad():\n",
    "            for batch_idx, (images, labels) in enumerate(val_loader):\n",
    "                actual_val_batch_count = batch_idx + 1\n",
    "                \n",
    "                valid_mask = validate_labels(labels, config.NUM_CLASSES)\n",
    "                valid_count = int(jt.sum(valid_mask))\n",
    "                \n",
    "                if valid_count == 0:\n",
    "                    val_skipped += 1\n",
    "                    continue\n",
    "                \n",
    "                if valid_count < len(labels):\n",
    "                    images = images[valid_mask]\n",
    "                    labels = labels[valid_mask]\n",
    "                \n",
    "                outputs = model(images)\n",
    "                if jt.isnan(outputs).any():\n",
    "                    val_skipped += 1\n",
    "                    continue\n",
    "                \n",
    "                loss = nn.cross_entropy_loss(outputs, labels)\n",
    "                val_loss_sum += float(loss)\n",
    "                val_acc_sum += calculate_accuracy(outputs, labels)\n",
    "                val_batches += 1\n",
    "                \n",
    "                # âœ… ç»Ÿè®¡å„ç±»åˆ«\n",
    "                preds = jt.argmax(outputs, dim=1)[0].numpy()\n",
    "                labels_np = labels.numpy()\n",
    "                for pred, label in zip(preds, labels_np):\n",
    "                    label = int(label)\n",
    "                    pred = int(pred)\n",
    "                    if 0 <= label < config.NUM_CLASSES:\n",
    "                        class_total[label] += 1\n",
    "                        if pred == label:\n",
    "                            class_correct[label] += 1\n",
    "                \n",
    "                if (batch_idx + 1) % 20 == 0:\n",
    "                    avg_loss = val_loss_sum / val_batches if val_batches > 0 else 0\n",
    "                    avg_acc = val_acc_sum / val_batches if val_batches > 0 else 0\n",
    "                    \n",
    "                    if total_val_batches is not None:\n",
    "                        suffix = f\"Loss: {avg_loss:.4f} | Acc: {avg_acc*100:.1f}%\"\n",
    "                        print_progress_bar(batch_idx + 1, total_val_batches, prefix='  è¿›åº¦', suffix=suffix)\n",
    "                    else:\n",
    "                        suffix = f\"Loss: {avg_loss:.4f} | Acc: {avg_acc*100:.1f}%\"\n",
    "                        print(f'\\r  è¿›åº¦: {batch_idx+1} batches | {suffix}', end='', flush=True)\n",
    "        \n",
    "        if total_val_batches is None:\n",
    "            total_val_batches = actual_val_batch_count\n",
    "            print(f\"\\n\\n  â„¹ï¸  æ£€æµ‹åˆ°éªŒè¯é›†å®é™…batchæ•°: {total_val_batches}\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        val_time = time.time() - val_start\n",
    "        \n",
    "        if val_batches > 0:\n",
    "            avg_val_loss = val_loss_sum / val_batches\n",
    "            avg_val_acc = val_acc_sum / val_batches\n",
    "            \n",
    "            # âœ… è®¡ç®—çœŸå®å‡†ç¡®ç‡ï¼ˆåŸºäºç±»åˆ«ç»Ÿè®¡ï¼‰\n",
    "            total_correct = int(np.sum(class_correct))\n",
    "            total_samples = int(np.sum(class_total))\n",
    "            real_acc = total_correct / total_samples if total_samples > 0 else 0.0\n",
    "            \n",
    "            # å¹³è¡¡å‡†ç¡®ç‡\n",
    "            class_accs = []\n",
    "            for i in range(config.NUM_CLASSES):\n",
    "                if class_total[i] > 0:\n",
    "                    acc = class_correct[i] / class_total[i]\n",
    "                    class_accs.append(acc)\n",
    "            balanced_acc = np.mean(class_accs) if class_accs else 0.0\n",
    "            \n",
    "            print(f\"\\n  âœ… éªŒè¯å®Œæˆ ({val_time:.1f}ç§’)\")\n",
    "            print(f\"     éå†: {actual_val_batch_count} batches\")\n",
    "            print(f\"     æœ‰æ•ˆ: {val_batches} batches\")\n",
    "            print(f\"     æ ·æœ¬: {total_samples} ä¸ª (æ­£ç¡®: {total_correct})\")\n",
    "            print(f\"     Loss: {avg_val_loss:.4f}\")\n",
    "            # âœ… åŒæ—¶æ˜¾ç¤ºä¸¤ç§å‡†ç¡®ç‡\n",
    "            print(f\"     å‡†ç¡®ç‡: {real_acc*100:.2f}% (ç±»åˆ«ç»Ÿè®¡)\")\n",
    "            if abs(real_acc - avg_val_acc) > 0.01:  # å¦‚æœå·®å¼‚>1%ï¼Œæ˜¾ç¤ºè­¦å‘Š\n",
    "                print(f\"     âš ï¸  Batchå¹³å‡: {avg_val_acc*100:.2f}% (å¯èƒ½ä¸å‡†ç¡®)\")\n",
    "            print(f\"     å¹³è¡¡å‡†ç¡®ç‡: {balanced_acc*100:.2f}%\")\n",
    "            if val_skipped > 0:\n",
    "                print(f\"     è·³è¿‡: {val_skipped} ä¸ªå¼‚å¸¸batch\")\n",
    "            print(flush=True)\n",
    "            \n",
    "            # æ¯5è½®æ˜¾ç¤ºç±»åˆ«è¯¦æƒ…\n",
    "            if (epoch + 1) % 5 == 0 or epoch == EPOCHS - 1:\n",
    "                print(f\"\\n  ğŸ“Š å„ç±»åˆ«å‡†ç¡®ç‡:\")\n",
    "                for i in range(config.NUM_CLASSES):\n",
    "                    if i < len(CLASS_NAMES):\n",
    "                        if class_total[i] > 0:\n",
    "                            acc = class_correct[i] / class_total[i] * 100\n",
    "                            correct_count = int(class_correct[i])\n",
    "                            total_count = int(class_total[i])\n",
    "                            print(f\"     {CLASS_NAMES[i]:<28}: {acc:>5.1f}% ({correct_count}/{total_count})\")\n",
    "                        else:\n",
    "                            print(f\"     {CLASS_NAMES[i]:<28}: {'N/A':>5} (0/0)\")\n",
    "                \n",
    "                # âœ… æ˜¾ç¤ºéªŒè¯ä¿¡æ¯\n",
    "                print(f\"\\n  â„¹ï¸  å‡†ç¡®ç‡éªŒè¯:\")\n",
    "                print(f\"     å„ç±»æ­£ç¡®æ•°æ€»å’Œ: {total_correct}\")\n",
    "                print(f\"     å„ç±»æ ·æœ¬æ•°æ€»å’Œ: {total_samples}\")\n",
    "                print(f\"     æ‰‹åŠ¨è®¡ç®—å‡†ç¡®ç‡: {total_correct}/{total_samples} = {real_acc*100:.2f}%\")\n",
    "            \n",
    "            # âœ… ä½¿ç”¨çœŸå®å‡†ç¡®ç‡ä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "            if balanced_acc > best_balanced_acc:\n",
    "                improvement = (balanced_acc - best_balanced_acc) * 100\n",
    "                best_balanced_acc = balanced_acc\n",
    "                best_acc = real_acc  # âœ… ä½¿ç”¨çœŸå®å‡†ç¡®ç‡\n",
    "                model_path = os.path.join(save_dir, 'best_model.pkl')\n",
    "                jt.save(model.state_dict(), model_path)\n",
    "                print(f\"\\n  ğŸ‰ æ–°æœ€ä½³! å¹³è¡¡å‡†ç¡®ç‡: {balanced_acc*100:.2f}% (â†‘{improvement:.2f}%)\", flush=True)\n",
    "        \n",
    "        # Epochæ€»ç»“\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_elapsed = time.time() - total_start_time\n",
    "        avg_epoch_time = total_elapsed / (epoch + 1)\n",
    "        remaining = avg_epoch_time * (EPOCHS - epoch - 1)\n",
    "        \n",
    "        print(f\"\\n  â±ï¸  æœ¬è½®: {epoch_time/60:.1f}min | å·²ç”¨: {total_elapsed/60:.1f}min | å‰©ä½™: {remaining/60:.1f}min\")\n",
    "        print(f\"  ğŸ“… é¢„è®¡å®Œæˆ: {time.strftime('%H:%M:%S', time.localtime(time.time() + remaining))}\", flush=True)\n",
    "    \n",
    "    # å®Œæˆ\n",
    "    total_time = time.time() - total_start_time\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ğŸŠ è®­ç»ƒå®Œæˆ! æ€»è€—æ—¶: {total_time/60:.1f}åˆ†é’Ÿ\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"æœ€ä½³å‡†ç¡®ç‡: {best_acc*100:.2f}%\")\n",
    "    print(f\"æœ€ä½³å¹³è¡¡å‡†ç¡®ç‡: {best_balanced_acc*100:.2f}%\")\n",
    "    print(f\"æ¨¡å‹ä¿å­˜: {os.path.join(save_dir, 'best_model.pkl')}\")\n",
    "    print(f\"{'='*70}\\n\", flush=True)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f04354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
