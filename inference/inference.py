"""
ç®€æ´ç‰ˆæ¨ç†è„šæœ¬ - å¯ç›´æ¥è°ƒç”¨
"""

import os
import sys
import jittor as jt
from jittor import nn
import numpy as np
from PIL import Image
import json

current_dir = os.path.abspath('.')
project_root = os.path.dirname(current_dir)

if project_root in sys.path:
    sys.path.remove(project_root)

sys.path.insert(0, project_root)

from data_loader import get_dataloader, CLASS_NAMES
from models.vit_model import Visual_Transformer
from config import Config


class TomatoPredictor:
    def __init__(self, model_path, device='gpu'):
        """åˆå§‹åŒ–é¢„æµ‹å™¨"""
        self.config = Config()
        jt.flags.use_cuda = 1 if device == 'gpu' and jt.has_cuda else 0
        
        print(f"ğŸ“¦ åŠ è½½æ¨¡å‹: {model_path}")
        
        # åˆ›å»ºæ¨¡å‹
        self.model = Visual_Transformer(
            img_size=self.config.IMG_SIZE,
            patch_size=self.config.PATCH_SIZE,
            in_channels=self.config.IN_CHANNELS,
            embed_dim=self.config.EMBED_DIM,
            depth=self.config.NUM_LAYERS,
            num_heads=self.config.NUM_HEADS,
            dropout_rate=0.1,
            hidden_dim=self.config.MLP_Hidden_Dim
        )
        
        # åŠ è½½æƒé‡
        state_dict = jt.load(model_path)
        self.model.load_state_dict(state_dict)
        self.model.eval()
        
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ (è®¾å¤‡: {'GPU' if jt.flags.use_cuda else 'CPU'})\n")
    
    def preprocess_image(self, image_path):
        """é¢„å¤„ç†å•å¼ å›¾ç‰‡"""
        img = Image.open(image_path).convert('RGB')
        img = img.resize((self.config.IMG_SIZE, self.config.IMG_SIZE))
        
        # è½¬ä¸ºæ•°ç»„å¹¶å½’ä¸€åŒ–
        img_array = np.array(img).astype(np.float32) / 255.0
        
        # æ ‡å‡†åŒ–
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        img_array = (img_array - mean) / std
        
        # è½¬ä¸º (C, H, W)
        img_array = img_array.transpose(2, 0, 1)
        img_tensor = jt.array(img_array[np.newaxis, :])
        
        return img_tensor
    
    def predict_single(self, image_path, top_k=3, verbose=True):
        """
        é¢„æµ‹å•å¼ å›¾ç‰‡
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            top_k: è¿”å›å‰kä¸ªé¢„æµ‹
            verbose: æ˜¯å¦æ‰“å°ç»“æœ
            
        Returns:
            [(ç±»åˆ«å, ç½®ä¿¡åº¦), ...]
        """
        img_tensor = self.preprocess_image(image_path)
        
        with jt.no_grad():
            outputs = self.model(img_tensor)
            probabilities = nn.softmax(outputs, dim=1)[0].numpy()
        
        # è·å– top-k
        top_k_indices = np.argsort(probabilities)[::-1][:top_k]
        predictions = [
            (CLASS_NAMES[idx] if idx < len(CLASS_NAMES) else f"Class_{idx}", 
             float(probabilities[idx]))
            for idx in top_k_indices
        ]
        
        if verbose:
            print(f"{'='*70}")
            print(f"ğŸ” æ¨ç†: {os.path.basename(image_path)}")
            print(f"{'='*70}\n")
            print("ğŸ“Š é¢„æµ‹ç»“æœ:\n")
            for i, (class_name, confidence) in enumerate(predictions, 1):
                bar_length = int(confidence * 40)
                bar = 'â–ˆ' * bar_length + 'â–‘' * (40 - bar_length)
                print(f"  {i}. {class_name:<30} |{bar}| {confidence*100:>6.2f}%")
            print()
        
        return predictions
    
    def predict_batch(self, image_folder, output_file=None, verbose=True):
        """
        æ‰¹é‡æ¨ç†æ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡
        
        Args:
            image_folder: å›¾ç‰‡æ–‡ä»¶å¤¹
            output_file: ä¿å­˜ç»“æœçš„jsonæ–‡ä»¶
            verbose: æ˜¯å¦æ‰“å°è¿›åº¦
        """
        # è·å–å›¾ç‰‡æ–‡ä»¶
        image_exts = {'.jpg', '.jpeg', '.png', '.bmp'}
        image_files = [
            f for f in os.listdir(image_folder)
            if os.path.splitext(f)[1].lower() in image_exts
        ]
        
        if not image_files:
            print(f"âŒ åœ¨ {image_folder} ä¸­æœªæ‰¾åˆ°å›¾ç‰‡")
            return None
        
        if verbose:
            print(f"ğŸ“‚ æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡\n")
        
        results = {}
        
        for i, img_file in enumerate(image_files, 1):
            img_path = os.path.join(image_folder, img_file)
            
            try:
                predictions = self.predict_single(img_path, top_k=1, verbose=False)
                class_name, confidence = predictions[0]
                
                results[img_file] = {
                    'predicted_class': class_name,
                    'confidence': confidence
                }
                
                if verbose:
                    print(f"[{i}/{len(image_files)}] {img_file:<30} -> {class_name:<30} ({confidence*100:.2f}%)")
                
            except Exception as e:
                if verbose:
                    print(f"[{i}/{len(image_files)}] {img_file:<30} -> âŒ é”™è¯¯: {e}")
                results[img_file] = {'error': str(e)}
        
        # ä¿å­˜ç»“æœ
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            if verbose:
                print(f"\nâœ… ç»“æœå·²ä¿å­˜: {output_file}")
        
        # ç»Ÿè®¡
        if verbose:
            print(f"\n{'='*70}")
            print("ğŸ“Š é¢„æµ‹ç»Ÿè®¡")
            print(f"{'='*70}")
            
            class_counts = {}
            total = 0
            for result in results.values():
                if 'predicted_class' in result:
                    cls = result['predicted_class']
                    class_counts[cls] = class_counts.get(cls, 0) + 1
                    total += 1
            
            for cls, count in sorted(class_counts.items(), key=lambda x: x[1], reverse=True):
                percentage = count / total * 100 if total > 0 else 0
                print(f"  {cls:<30}: {count:>4} ({percentage:>5.1f}%)")
            print()
        
        return results
    
    def evaluate_testset(self, data_root, batch_size=8, verbose=True):
        """
        åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
        
        Args:
            data_root: æ•°æ®é›†æ ¹ç›®å½•
            batch_size: æ‰¹æ¬¡å¤§å°
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        """
        if verbose:
            print("ğŸ“¦ åŠ è½½æµ‹è¯•é›†...")
        
        test_loader = get_dataloader(
            root_dir=data_root,
            mode='test',
            batch_size=batch_size,
            img_size=self.config.IMG_SIZE,
            shuffle=False,
            num_workers=0,
            sample_ratio=1.0
        )
        
        if verbose:
            print("ğŸ” è¯„ä¼°ä¸­...\n")
        
        # ç»Ÿè®¡å˜é‡
        class_correct = np.zeros(self.config.NUM_CLASSES, dtype=np.int64)
        class_total = np.zeros(self.config.NUM_CLASSES, dtype=np.int64)
        
        processed = 0
        
        with jt.no_grad():
            for batch_idx, (images, labels) in enumerate(test_loader):
                # è¿‡æ»¤æ— æ•ˆæ ‡ç­¾
                valid_mask = (labels.numpy() >= 0) & (labels.numpy() < self.config.NUM_CLASSES)
                
                if not valid_mask.any():
                    continue
                
                images = images[jt.array(valid_mask)]
                labels = labels[jt.array(valid_mask)]
                
                # æ¨ç†
                outputs = self.model(images)
                preds = jt.argmax(outputs, dim=1)[0].numpy()
                labels_np = labels.numpy()
                
                # ç»Ÿè®¡
                for pred, label in zip(preds, labels_np):
                    label = int(label)
                    pred = int(pred)
                    if 0 <= label < self.config.NUM_CLASSES:
                        class_total[label] += 1
                        if pred == label:
                            class_correct[label] += 1
                
                processed += len(labels_np)
                
                # è¿›åº¦æ˜¾ç¤º
                if verbose and (batch_idx + 1) % 20 == 0:
                    current_acc = class_correct.sum() / class_total.sum() if class_total.sum() > 0 else 0
                    print(f"  å¤„ç†: {processed} æ ·æœ¬ | å½“å‰å‡†ç¡®ç‡: {current_acc*100:.2f}%")
        
        # è®¡ç®—ç»“æœ
        total_correct = int(class_correct.sum())
        total_samples = int(class_total.sum())
        overall_acc = total_correct / total_samples if total_samples > 0 else 0
        
        # è®¡ç®—å¹³è¡¡å‡†ç¡®ç‡
        class_accs = []
        for i in range(self.config.NUM_CLASSES):
            if class_total[i] > 0:
                class_accs.append(class_correct[i] / class_total[i])
        balanced_acc = np.mean(class_accs) if class_accs else 0
        
        # æ‰“å°ç»“æœ
        if verbose:
            print(f"\n{'='*70}")
            print("ğŸ“Š è¯„ä¼°ç»“æœ")
            print(f"{'='*70}")
            print(f"æ€»æ ·æœ¬æ•°: {total_samples}")
            print(f"æ­£ç¡®é¢„æµ‹: {total_correct}")
            print(f"æ€»ä½“å‡†ç¡®ç‡: {overall_acc*100:.2f}%")
            print(f"å¹³è¡¡å‡†ç¡®ç‡: {balanced_acc*100:.2f}%")
            
            print(f"\n{'='*70}")
            print("ğŸ“‹ å„ç±»åˆ«è¯¦ç»†ç»“æœ")
            print(f"{'='*70}")
            print(f"{'ç±»åˆ«':<30} {'å‡†ç¡®ç‡':>10} {'æ­£ç¡®/æ€»æ•°':>15}")
            print(f"{'-'*70}")
            
            for i in range(self.config.NUM_CLASSES):
                if i < len(CLASS_NAMES):
                    class_name = CLASS_NAMES[i]
                    if class_total[i] > 0:
                        acc = class_correct[i] / class_total[i] * 100
                        print(f"{class_name:<30} {acc:>9.2f}% {int(class_correct[i]):>7}/{int(class_total[i]):<7}")
                    else:
                        print(f"{class_name:<30} {'N/A':>10} {'0/0':>15}")
            print()
        
        return {
            'overall_accuracy': overall_acc,
            'balanced_accuracy': balanced_acc,
            'class_correct': class_correct,
            'class_total': class_total,
            'total_samples': total_samples
        }


# ========== ä¾¿æ·å‡½æ•° ==========

def predict_image(model_path, image_path, top_k=5, device='gpu'):
    """å¿«é€Ÿé¢„æµ‹å•å¼ å›¾ç‰‡"""
    predictor = TomatoPredictor(model_path, device=device)
    return predictor.predict_single(image_path, top_k=top_k)


def predict_folder(model_path, folder_path, output_file=None, device='gpu'):
    """å¿«é€Ÿé¢„æµ‹æ–‡ä»¶å¤¹"""
    predictor = TomatoPredictor(model_path, device=device)
    return predictor.predict_batch(folder_path, output_file=output_file)


def evaluate_model(model_path, data_root, batch_size=8, device='gpu'):
    """å¿«é€Ÿè¯„ä¼°æ¨¡å‹"""
    predictor = TomatoPredictor(model_path, device=device)
    return predictor.evaluate_testset(data_root, batch_size=batch_size)